#!/usr/bin/env python3
"""
Tixcraft çµ‚æ¥µçˆ¬èŸ²ç³»çµ±ï¼ˆv5.0ï¼‰
ä½œè€…: Assistant
æ—¥æœŸ: 2026-02-25
åŠŸèƒ½: 
- ç²¾ç¢ºã€Œè¡Œã€åˆ†æµé‚è¼¯ï¼šé¿å…é‡è¤‡èˆ‡èª¤æŠ“
- JSè¼‰å…¥å„ªåŒ–ï¼šWebDriverWait ç›£æ§ dataLayer.artistName
- å³æ™‚å¯«å…¥ï¼šæ¯å€‹URLçˆ¬å®Œç«‹åˆ»ä¿å­˜ï¼Œé¿å…è³‡æ–™éºå¤±
- æ™ºèƒ½å ´é¤¨è¾¨è­˜ï¼šéæ¿¾æ–‡å®£ï¼Œä¿ç•™æ ¸å¿ƒåœ°é»è³‡è¨Š
- å¼·åŒ–æ¨™é¡Œæ©Ÿåˆ¶ï¼šJS â†’ HTML â†’ ä¿åº•ä¸‰å±¤ç­–ç•¥
"""

from time import sleep
from datetime import datetime
import json
import re
import os
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager


class TixcraftUltimateCrawler:
    """Tixcraft çµ‚æ¥µçˆ¬èŸ²ç³»çµ±ï¼ˆç²¾ç¢ºåˆ†æµç‰ˆï¼‰"""
    
    def __init__(self, base_url="https://tixcraft.com/activity"):
        self.base_url = base_url
        self.driver = self._setup_driver()
        self.json_filename = 'tixcraft_activities_ultimate.json'
        self.current_data = self._load_existing_data()
    
    def _load_existing_data(self):
        """è¼‰å…¥ç¾æœ‰çš„JSONè³‡æ–™ï¼Œæ”¯æ´æ–·é»çºŒçˆ¬"""
        if os.path.exists(self.json_filename):
            try:
                with open(self.json_filename, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    print(f"ğŸ“‚ è¼‰å…¥ç¾æœ‰è³‡æ–™ï¼š{len(data.get('events', []))} å€‹æ´»å‹•")
                    return data
            except Exception as e:
                print(f"âš ï¸ è¼‰å…¥ç¾æœ‰è³‡æ–™å¤±æ•—ï¼š{e}")
        
        return {
            'scrape_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_events': 0,
            'events': []
        }
    
    def _save_single_event(self, event_data):
        """å³æ™‚ä¿å­˜å–®å€‹æ´»å‹•è³‡æ–™"""
        try:
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒURLçš„è³‡æ–™
            existing_urls = [event['url'] for event in self.current_data['events']]
            if event_data['url'] not in existing_urls:
                self.current_data['events'].append(event_data)
                self.current_data['total_events'] = len(self.current_data['events'])
                self.current_data['last_update'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                # ç«‹åˆ»å¯«å…¥æª”æ¡ˆ
                with open(self.json_filename, 'w', encoding='utf-8') as f:
                    json.dump(self.current_data, f, ensure_ascii=False, indent=2)
                
                print(f"ğŸ’¾ å³æ™‚ä¿å­˜ï¼šç¬¬ {event_data['index']} å€‹æ´»å‹•å·²å­˜å…¥ {self.json_filename}")
                return True
            else:
                print(f"âš ï¸ ç¬¬ {event_data['index']} å€‹æ´»å‹•å·²å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­ï¼Œè·³éé‡è¤‡ä¿å­˜")
                return False
        except Exception as e:
            print(f"âŒ å³æ™‚ä¿å­˜å¤±æ•—ï¼š{e}")
            return False
    
    def clean_text(self, text):
        """æ¸…ç†æ–‡å­—ï¼šç§»é™¤å¤šé¤˜ç©ºæ ¼ã€æ›è¡Œç¬¦è™Ÿã€ç‰¹æ®Šå­—ç¬¦"""
        if not text:
            return ""
        
        # ç§»é™¤å¤šé¤˜ç©ºæ ¼å’Œæ›è¡Œç¬¦è™Ÿ
        cleaned = re.sub(r'\s+', ' ', text.strip())
        
        # ç§»é™¤å¤šé¤˜çš„æ¨™é»ç¬¦è™Ÿé‡è¤‡
        cleaned = re.sub(r'[;,ï¼Œï¼›]{2,}', ';', cleaned)
        
        # ç§»é™¤é–‹é ­çµå°¾çš„åˆ†è™Ÿæˆ–é€—è™Ÿ
        cleaned = re.sub(r'^[;,ï¼Œï¼›\s]+|[;,ï¼Œï¼›\s]+$', '', cleaned)
        
        return cleaned.strip()
    
    def get_data_from_js_optimized(self):
        """JSè¼‰å…¥å„ªåŒ–ï¼šWebDriverWaitç›£æ§dataLayer.artistName"""
        print("ğŸ” æ­£åœ¨ä½¿ç”¨WebDriverWaitç›£æ§JavaScript dataLayer...")
        
        try:
            def check_artist_name(driver):
                """æª¢æŸ¥dataLayerä¸­æ˜¯å¦å­˜åœ¨artistName"""
                try:
                    result = driver.execute_script("""
                        if (typeof dataLayer !== 'undefined' && dataLayer.length > 0) {
                            for (let i = 0; i < dataLayer.length; i++) {
                                if (dataLayer[i].artistName) {
                                    return dataLayer[i].artistName;
                                }
                            }
                        }
                        return null;
                    """)
                    return result
                except:
                    return None
            
            # ä½¿ç”¨WebDriverWaitç­‰å¾…æœ€å¤š10ç§’
            wait = WebDriverWait(self.driver, 10)
            
            # æ¯0.5ç§’æª¢æŸ¥ä¸€æ¬¡dataLayer
            for attempt in range(20):  # 10ç§’ / 0.5ç§’ = 20æ¬¡å˜—è©¦
                artist_name = check_artist_name(self.driver)
                if artist_name:
                    print(f"âœ… JSæˆåŠŸæå–æ¨™é¡Œï¼š{artist_name}")
                    return artist_name
                sleep(0.5)
                print(f"â³ ç­‰å¾…dataLayerè¼‰å…¥... ({attempt+1}/20)")
            
            print("âŒ 10ç§’ç­‰å¾…å¾Œï¼ŒdataLayerä»æœªè¼‰å…¥artistName")
            return None
            
        except Exception as e:
            print(f"âŒ JSè¼‰å…¥ç›£æ§å¤±æ•—ï¼š{e}")
            return None
    
    def get_fallback_title_enhanced(self):
        """å¢å¼·ç‰ˆä¿åº•æ¨™é¡Œæå–"""
        try:
            page_title = self.driver.title
            if page_title and len(page_title.strip()) > 0:
                # ä½¿ç”¨split('-')[0]æå–æ¨™é¡Œçš„ç¬¬ä¸€éƒ¨åˆ†
                clean_title = page_title.split('-')[0].strip()
                
                # é€²ä¸€æ­¥æ¸…ç†å¸¸è¦‹çš„ç¶²ç«™å¾Œç¶´
                clean_title = re.sub(r'(\s*[\|ï½œ]\s*.*)|(\s*-\s*.*)', '', clean_title)
                clean_title = clean_title.replace('æ‹“å…ƒå”®ç¥¨', '').replace('tixcraft', '').strip()
                
                if clean_title and len(clean_title) > 2:
                    print(f"âœ… ä¿åº•æ¨™é¡Œæå–æˆåŠŸï¼š{clean_title}")
                    return clean_title
            
            print("âš ï¸ ç¶²é æ¨™é¡Œç‚ºç©ºæˆ–éçŸ­ï¼Œä½¿ç”¨é è¨­å€¼")
            return "è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜"
            
        except Exception as e:
            print(f"âŒ ä¿åº•æ¨™é¡Œæå–å¤±æ•—ï¼š{e}")
            return "è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜"
    
    def classify_content_precisely(self, text_content):
        """ç²¾ç¢ºå…§å®¹åˆ†æµï¼šé¿å…é‡è¤‡èˆ‡èª¤æŠ“"""
        
        if not text_content:
            return {
                'event_datetime': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
                'sale_info': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜', 
                'location': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
                'price': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜'
            }
        
        # åˆ†è¡Œè™•ç†
        lines = [line.strip() for line in text_content.split('\n') if line.strip()]
        
        # è³‡æ–™åˆ†é¡å®¹å™¨
        event_datetime_info = []
        sale_info_list = []
        location_info = []
        price_info = []
        
        print(f"\nğŸ” ã€ç²¾ç¢ºåˆ†æµã€‘æ­£åœ¨åˆ†æ {len(lines)} è¡Œå…§å®¹...")
        
        for line in lines:
            line = self.clean_text(line)
            if not line or len(line) < 4:  # å¿½ç•¥éçŸ­çš„è¡Œ
                continue
            
            print(f"   è™•ç†è¡Œï¼š{line[:60]}...")  # é¡¯ç¤ºå‰60å­—ç¬¦
            
            # === 1. event_datetime (æ´»å‹•æ™‚é–“) ===
            # æ•æ‰åŒ…å«æ—¥æœŸ/æ™‚é–“æ ¼å¼çš„è¡Œ
            datetime_patterns = [
                r'202[0-9]/\d{1,2}/\d{1,2}',  # 2026/01/01
                r'\d{1,2}æœˆ\d{1,2}æ—¥',        # 1æœˆ1æ—¥
                r'\d{1,2}:\d{2}',             # 19:00
                r'æ¼”å‡º.*?æ™‚é–“',                # æ¼”å‡ºæ™‚é–“
                r'æ´»å‹•.*?æ™‚é–“',                # æ´»å‹•æ™‚é–“
                r'Date.*?Time',               # Date/Time
            ]
            
            has_datetime = any(re.search(pattern, line, re.IGNORECASE) for pattern in datetime_patterns)
            
            # æ’é™¤æ¢ä»¶ï¼šåŒ…å«å”®ç¥¨ç›¸é—œé—œéµå­—
            exclude_sale_keywords = ['é–‹è³£', 'å”®ç¥¨', 'é å”®', 'å•Ÿå”®', 'å…¨é¢é–‹è³£', 'æ¸…ç¥¨', 'é è³¼', 'è³¼ç¥¨']
            has_sale_keyword = any(keyword in line for keyword in exclude_sale_keywords)
            
            if has_datetime and not has_sale_keyword:
                event_datetime_info.append(line)
                print(f"     â¤ æ­¸é¡ç‚ºï¼šæ´»å‹•æ™‚é–“")
                continue
            
            # === 2. sale_info (å”®ç¥¨è³‡è¨Š) ===
            sale_patterns = [
                r'é–‹è³£',
                r'å”®ç¥¨æ™‚é–“',
                r'é å”®',
                r'å•Ÿå”®',
                r'å…¨é¢é–‹è³£',
                r'é è³¼',
                r'è³¼ç¥¨.*?æ™‚é–“',
                r'æœƒå“¡.*?è³¼',
                r'ä¸€èˆ¬.*?å”®',
            ]
            
            has_sale_pattern = any(re.search(pattern, line, re.IGNORECASE) for pattern in sale_patterns)
            has_date = re.search(r'202[0-9]|\d{1,2}æœˆ\d{1,2}æ—¥|\d{1,2}/\d{1,2}', line)
            
            if has_sale_pattern and has_date:
                sale_info_list.append(line)
                print(f"     â¤ æ­¸é¡ç‚ºï¼šå”®ç¥¨è³‡è¨Š")
                continue
            
            # === 3. location (åœ°é»ç²¾ç¢ºåŒ–) ===
            venue_keywords = ['é¤¨', 'å·¨è›‹', 'ä¸­å¿ƒ', 'Legacy', 'Zepp', 'æ»‘é›ªå ´', 'Sub Live', 'Exhibition Hall', 
                             'Arena', 'TICC', 'é«”è‚²', 'æœƒè­°', 'éŸ³æ¨‚', 'å±•è¦½', 'WESTAR', 'åœ‹éš›']
            
            has_venue = any(keyword in line for keyword in venue_keywords)
            is_too_long = len(line) > 60  # éé•·çš„é€šå¸¸æ˜¯æ–‡å®£
            
            # æ’é™¤æ–‡å®£æ€§è³ªçš„é•·æ–‡
            if has_venue and not is_too_long:
                # é€²ä¸€æ­¥æª¢æŸ¥æ˜¯å¦ç‚ºåœ°é»ç›¸é—œ
                location_indicators = ['åœ°é»', 'å ´åœ°', 'Venue', 'æ¼”å‡ºåœ°', 'æ´»å‹•åœ°', 'æœƒå ´']
                is_location = any(indicator in line for indicator in location_indicators) or has_venue
                
                if is_location:
                    location_info.append(line)
                    print(f"     â¤ æ­¸é¡ç‚ºï¼šæ´»å‹•åœ°é»")
                    continue
            
            # === 4. price (ç¥¨åƒ¹) ===
            price_patterns = [
                r'NT\$\d+',                    # NT$2000
                r'\d+å…ƒ',                      # 2000å…ƒ
                r'\$\d+',                      # $2000
                r'ç¥¨åƒ¹',                       # ç¥¨åƒ¹
                r'VIP.*?\d+',                  # VIP 2000
                r'åƒ¹æ ¼',                       # åƒ¹æ ¼
                r'\d+(?:,\d{3})*å…ƒ',          # 2,000å…ƒ
            ]
            
            has_price = any(re.search(pattern, line, re.IGNORECASE) for pattern in price_patterns)
            
            # æ’é™¤è¦å‰‡æ€§æ–‡å­—
            exclude_price_keywords = ['å§“å', 'æœƒå“¡è³‡æ–™', 'é™è³¼', 'æœå‹™è²»', 'æ‰‹çºŒè²»', 'é€€ç¥¨', 'è¦å®š', 'æ³¨æ„']
            has_exclude_keyword = any(keyword in line for keyword in exclude_price_keywords)
            
            if has_price and not has_exclude_keyword:
                price_info.append(line)
                print(f"     â¤ æ­¸é¡ç‚ºï¼šç¥¨åƒ¹è³‡è¨Š")
                continue
            
            print(f"     â¤ æœªæ­¸é¡ï¼ˆè·³éï¼‰")
        
        # === ä¿åº•æ©Ÿåˆ¶ï¼šsale_info ç‚ºç©ºæ™‚çš„é¡å¤–æª¢æŸ¥ ===
        if not sale_info_list:
            print("âš ï¸ å”®ç¥¨è³‡è¨Šç‚ºç©ºï¼Œå•Ÿå‹•ä¿åº•æ©Ÿåˆ¶...")
            for line in lines:
                # å°‹æ‰¾å¸¸è¦‹å”®ç¥¨æ™‚é–“æ ¼å¼
                if re.search(r'\d{1,2}:\d{2}.*?(å”®|è³£)', line) or re.search(r'(å”®|è³£).*?\d{1,2}:\d{2}', line):
                    sale_info_list.append(line)
                    print(f"âœ… ä¿åº•æ©Ÿåˆ¶æ‰¾åˆ°å”®ç¥¨æ™‚é–“ï¼š{line[:50]}...")
                    break
        
        # çµ„è£çµæœ
        result = {
            'event_datetime': '; '.join(event_datetime_info) if event_datetime_info else 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'sale_info': '; '.join(sale_info_list) if sale_info_list else 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'location': '; '.join(location_info) if location_info else 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'price': '; '.join(price_info) if price_info else 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜'
        }
        
        # è¼¸å‡ºåˆ†é¡çµ±è¨ˆ
        print(f"\nğŸ“Š ã€åˆ†é¡çµ±è¨ˆã€‘")
        print(f"   ğŸ—“ï¸ æ´»å‹•æ™‚é–“: {len(event_datetime_info)} æ¢")
        print(f"   ğŸŸï¸ å”®ç¥¨è³‡è¨Š: {len(sale_info_list)} æ¢")
        print(f"   ğŸ“ æ´»å‹•åœ°é»: {len(location_info)} æ¢")
        print(f"   ğŸ’° ç¥¨åƒ¹è³‡è¨Š: {len(price_info)} æ¢")
        
        return result
    
    def extract_alternative_content(self):
        """å‚™ç”¨è³‡æ–™æŠ“å–ï¼šå˜—è©¦å¾å¤šç¨®HTMLå…ƒç´ ç²å–è³‡è¨Š"""
        try:
            print("ğŸ”„ æ­£åœ¨å˜—è©¦å‚™ç”¨è³‡æ–™æŠ“å–æ–¹æ³•...")
            
            # æ–¹æ³•1: æŠ“å–æ‰€æœ‰pæ¨™ç±¤
            p_elements = self.driver.find_elements(By.TAG_NAME, "p")
            p_content = ""
            
            for p in p_elements:
                text = p.text.strip()
                if text and len(text) > 10:
                    p_content += text + "\n"
            
            if p_content and len(p_content) > 50:
                print(f"âœ… å¾ {len(p_elements)} å€‹ p æ¨™ç±¤ä¸­æå–åˆ°å…§å®¹")
                return p_content
            
            # æ–¹æ³•2: æŠ“å–divå®¹å™¨å…§å®¹
            div_selectors = [
                "div.content", "div.detail", "div.info", 
                ".event-info", ".activity-detail", "div.description"
            ]
            
            for selector in div_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        text = element.text.strip()
                        if text and len(text) > 30:
                            print(f"âœ… å¾ {selector} ä¸­æå–åˆ°å…§å®¹")
                            return text
                except:
                    continue
            
            # æ–¹æ³•3: æŠ“å–è¡¨æ ¼å…§å®¹
            table_elements = self.driver.find_elements(By.TAG_NAME, "table")
            table_content = ""
            
            for table in table_elements:
                text = table.text.strip()
                if text and len(text) > 20:
                    table_content += text + "\n"
            
            if table_content:
                print(f"âœ… å¾ {len(table_elements)} å€‹ table æ¨™ç±¤ä¸­æå–åˆ°å…§å®¹")
                return table_content
            
            print("âš ï¸ æ‰€æœ‰å‚™ç”¨æŠ“å–æ–¹æ³•éƒ½æœªæ‰¾åˆ°è¶³å¤ å…§å®¹")
            return None
            
        except Exception as e:
            print(f"âŒ å‚™ç”¨æŠ“å–æ–¹æ³•å¤±æ•—: {e}")
            return None
    
    def _setup_driver(self):
        """é…ç½®ä¸¦åˆå§‹åŒ–Chromeç€è¦½å™¨ï¼ˆé˜²åµæ¸¬ç‰ˆï¼‰"""
        print("\nğŸ”§ ã€ç€è¦½å™¨åˆå§‹åŒ–ã€‘æ­£åœ¨è¨­å®šChromeç€è¦½å™¨...")
        options = Options()
        
        # é˜²åµæ¸¬æ ¸å¿ƒè¨­å®š
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument("--disable-blink-features=AutomationControlled")
        
        # æ•ˆèƒ½èˆ‡ç©©å®šæ€§è¨­å®š
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        print("   âœ… é˜²åµæ¸¬èˆ‡æ•ˆèƒ½é¸é …é…ç½®å®Œæˆ")
        
        # å»ºç«‹Chromeç€è¦½å™¨å¯¦ä¾‹
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        
        # é€²éšJavaScripté˜²åµæ¸¬è¨­å®š
        driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
            'source': '''
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                })
            '''
        })
        
        driver.set_window_size(1920, 1080)
        print("   ğŸ›¡ï¸ JavaScripté˜²åµæ¸¬è¨­å®šå®Œæˆ")
        return driver
    
    def scrape_activity_list_enhanced(self):
        """å¢å¼·ç‰ˆæ´»å‹•åˆ—è¡¨æŠ“å–"""
        try:
            print(f"\nğŸŒ æ­£åœ¨è¼‰å…¥æ‹“å…ƒå”®ç¥¨æ´»å‹•åˆ—è¡¨é é¢...")
            self.driver.get(self.base_url)
            sleep(8)  # ç¢ºä¿JavaScriptå‹•æ…‹å…§å®¹å®Œå…¨è¼‰å…¥
            print("âœ… é é¢è¼‰å…¥å®Œæˆ")
            
            print("\nğŸ” æ­£åœ¨æœå°‹æ¼”å‡ºæ´»å‹•é€£çµï¼ˆå¤šé‡ç­–ç•¥ï¼‰...")
            
            activity_links = []
            
            # ç­–ç•¥1: æŒ‡å®šçš„ div.thumbnails a
            try:
                links = self.driver.find_elements(By.CSS_SELECTOR, "div.thumbnails a")
                if links:
                    activity_links.extend(links)
                    print(f"   ç­–ç•¥1 (div.thumbnails a): æ‰¾åˆ° {len(links)} å€‹é€£çµ")
            except Exception as e:
                print(f"   ç­–ç•¥1å¤±æ•—: {e}")
            
            # ç­–ç•¥2: æ‰€æœ‰åŒ…å« activity/detail çš„ a æ¨™ç±¤
            try:
                links = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='activity/detail']")
                if links:
                    activity_links.extend(links)
                    print(f"   ç­–ç•¥2 (a[href*='activity/detail']): æ‰¾åˆ° {len(links)} å€‹é€£çµ")
            except Exception as e:
                print(f"   ç­–ç•¥2å¤±æ•—: {e}")
            
            # ç­–ç•¥3: classåŒ…å«thumbnailç›¸é—œçš„å…ƒç´ 
            try:
                links = self.driver.find_elements(By.CSS_SELECTOR, "[class*='thumbnail'] a, [class*='thumb'] a")
                if links:
                    activity_links.extend(links)
                    print(f"   ç­–ç•¥3 ([class*='thumbnail'] a): æ‰¾åˆ° {len(links)} å€‹é€£çµ")
            except Exception as e:
                print(f"   ç­–ç•¥3å¤±æ•—: {e}")
            
            if not activity_links:
                print("âŒ æ‰€æœ‰ç­–ç•¥éƒ½æœªæ‰¾åˆ°ä»»ä½•æ¼”å‡ºé€£çµ")
                return []
            
            print(f"âœ… ç¸½å…±æ‰¾åˆ° {len(activity_links)} å€‹å€™é¸é€£çµ")
            
            # æå–å”¯ä¸€çš„é€£çµä¸¦éæ¿¾é‡è¤‡
            unique_urls = set()
            valid_links = []
            
            for link in activity_links:
                try:
                    url = link.get_attribute('href')
                    if url and ('activity/detail' in url or '/activity/' in url) and url not in unique_urls:
                        unique_urls.add(url)
                        valid_links.append(url)
                except Exception as e:
                    print(f"âŒ æå–é€£çµæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
            
            print(f"ğŸ“Š éæ¿¾é‡è¤‡å¾Œç²å¾—å”¯ä¸€é€£çµ {len(valid_links)} å€‹")
            
            # å¦‚æœé€£çµæ•¸å¤ªå°‘ï¼Œå˜—è©¦æ“´å±•æœå°‹
            if len(valid_links) < 30:
                print("âš ï¸ é€£çµæ•¸é‡åå°‘ï¼Œå˜—è©¦æ“´å±•æœå°‹...")
                try:
                    all_links = self.driver.find_elements(By.TAG_NAME, "a")
                    for link in all_links:
                        try:
                            url = link.get_attribute('href')
                            if url and ('/activity/' in url or 'tixcraft.com' in url) and 'detail' in url and url not in unique_urls:
                                unique_urls.add(url)
                                valid_links.append(url)
                        except:
                            continue
                    print(f"ğŸ“Š æ“´å±•æœå°‹å¾Œç²å¾—é€£çµ {len(valid_links)} å€‹")
                except Exception as e:
                    print(f"æ“´å±•æœå°‹å¤±æ•—: {e}")
            
            print(f"\nğŸ“‹ æ´»å‹•ç¶²å€æ¸…å–®ï¼š")
            for i, url in enumerate(valid_links, 1):
                print(f"   {i}. {url}")
            
            return valid_links
            
        except Exception as e:
            print(f"âŒ ç¬¬ä¸€å±¤çˆ¬å–éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return []
    
    def scrape_single_event_ultimate(self, url, index):
        """çµ‚æ¥µç‰ˆå–®å€‹æ´»å‹•è©³ç´°è³‡è¨Šçˆ¬å–"""
        
        print(f"\nğŸ” === ç¬¬ {index} å€‹æ´»å‹• ===")
        print(f"ğŸŒ æ­£åœ¨é€²å…¥: {url}")
        
        # åˆå§‹åŒ–è³‡æ–™çµæ§‹
        event_data = {
            'index': index,
            'title': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'event_datetime': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'sale_info': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'location': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜', 
            'price': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'url': url,
            'scrape_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        try:
            # å‰å¾€æ¼”å‡ºè©³æƒ…é é¢
            self.driver.get(url)
            sleep(3)  # ç­‰å¾…é é¢è¼‰å…¥
            
            # === æ¨™é¡ŒæŠ“å–ï¼šä¸‰å±¤å„ªå…ˆç­–ç•¥ ===
            title_found = False
            
            # å„ªå…ˆ1: JS dataLayer.artistName
            try:
                js_title = self.get_data_from_js_optimized()
                if js_title and len(js_title.strip()) > 0:
                    event_data['title'] = self.clean_text(js_title)
                    title_found = True
                    print(f"ğŸ­ æ¼”å‡ºé …ç›®åç¨± (JS): {event_data['title']}")
            except Exception as e:
                print(f"âš ï¸ JSæ¨™é¡Œæå–å¤±æ•—: {e}")
            
            # å„ªå…ˆ2: HTML synopsisEventTitle
            if not title_found:
                try:
                    title_element = self.driver.find_element(By.ID, "synopsisEventTitle")
                    if title_element.text and len(title_element.text.strip()) > 0:
                        event_data['title'] = self.clean_text(title_element.text)
                        title_found = True
                        print(f"ğŸ­ æ¼”å‡ºé …ç›®åç¨± (HTML): {event_data['title']}")
                except Exception as e:
                    print(f"âš ï¸ HTMLæ¨™é¡Œæå–å¤±æ•—: {e}")
            
            # å„ªå…ˆ3: ä¿åº•æ©Ÿåˆ¶
            if not title_found:
                event_data['title'] = self.get_fallback_title_enhanced()
                print(f"ğŸ­ æ¼”å‡ºé …ç›®åç¨± (ä¿åº•): {event_data['title']}")
            
            # === å…§å®¹æŠ“å–èˆ‡åˆ†é¡ ===
            content_found = False
            intro_text = ""
            
            # ä¸»è¦æ–¹æ³•ï¼šæŠ“å–introå…ƒç´ 
            try:
                intro_element = self.driver.find_element(By.ID, "intro")
                intro_text = intro_element.text.strip() if intro_element.text else ""
                
                if intro_text and len(intro_text) > 30:
                    content_found = True
                    print(f"âœ… å¾ intro å…ƒç´ æˆåŠŸæŠ“å–å…§å®¹ ({len(intro_text)} å­—ç¬¦)")
                else:
                    print(f"âš ï¸ intro å…ƒç´ å…§å®¹ä¸è¶³ï¼Œå˜—è©¦å‚™ç”¨æ–¹æ³•...")
                    
            except Exception as e:
                print(f"âš ï¸ ç„¡æ³•æŠ“å– intro å…ƒç´ : {e}")
            
            # å‚™ç”¨æ–¹æ³•ï¼šå…¶ä»–HTMLå…ƒç´ 
            if not content_found:
                alternative_content = self.extract_alternative_content()
                if alternative_content and len(alternative_content) > 30:
                    intro_text = alternative_content
                    content_found = True
                    print(f"âœ… å‚™ç”¨æ–¹æ³•æˆåŠŸç²å–å…§å®¹ ({len(intro_text)} å­—ç¬¦)")
                else:
                    print(f"âŒ æ‰€æœ‰æ–¹æ³•éƒ½ç„¡æ³•ç²å–è¶³å¤ å…§å®¹")
            
            # === ç²¾ç¢ºåˆ†æµè™•ç† ===
            if content_found and intro_text:
                print(f"\nğŸ“‹ ã€ç²¾ç¢ºåˆ†æµè™•ç†ã€‘")
                classified_info = self.classify_content_precisely(intro_text)
                
                # æ›´æ–°è³‡æ–™çµæ§‹
                event_data.update({
                    'event_datetime': classified_info['event_datetime'],
                    'sale_info': classified_info['sale_info'],
                    'location': classified_info['location'],
                    'price': classified_info['price']
                })
                
                # è¼¸å‡ºåˆ†é¡çµæœ
                print(f"\nğŸ“Š ã€åˆ†é¡çµæœã€‘")
                print("-" * 60)
                print(f"ğŸ—“ï¸ æ´»å‹•æ™‚é–“: {event_data['event_datetime'][:100]}...")
                print(f"ğŸŸï¸ å”®ç¥¨è³‡è¨Š: {event_data['sale_info'][:100]}...")
                print(f"ğŸ“ æ´»å‹•åœ°é»: {event_data['location'][:100]}...")
                print(f"ğŸ’° ç¥¨åƒ¹è³‡è¨Š: {event_data['price'][:100]}...")
                
            else:
                print(f"\nğŸ“‹ âš ï¸ æœªèƒ½ç²å–è¶³å¤ çš„è©³ç´°è³‡è¨Šï¼Œä¿æŒé è¨­å€¼")
            
            print(f"ğŸ”— æ´»å‹•ç¶²å€: {url}")
            
            # === å³æ™‚ä¿å­˜å–®å€‹æ´»å‹• ===
            save_success = self._save_single_event(event_data)
            
            if save_success:
                print(f"âœ… ç¬¬ {index} å€‹æ´»å‹•æŠ“å–ä¸¦ä¿å­˜å®Œæˆ")
                return True
            else:
                print(f"âš ï¸ ç¬¬ {index} å€‹æ´»å‹•æŠ“å–å®Œæˆä½†ä¿å­˜å¤±æ•—")
                return False
            
        except Exception as e:
            print(f"âŒ ç¬¬ {index} å€‹æ´»å‹•æŠ“å–å¤±æ•—: {e}")
            print(f"â­ï¸  è¨˜éŒ„å¤±æ•—è³‡æ–™ä¸¦è·³é...")
            
            # å³ä½¿å¤±æ•—ä¹Ÿè¦è¨˜éŒ„åŸºæœ¬è³‡è¨Š
            event_data['error'] = str(e)
            self._save_single_event(event_data)
            return False
    
    def run_ultimate_crawl(self):
        """åŸ·è¡Œçµ‚æ¥µç‰ˆæ™ºèƒ½åŒ–æ·±åº¦çˆ¬å–"""
        print("\nğŸŒŸ é–‹å§‹åŸ·è¡Œ Tixcraft çµ‚æ¥µçˆ¬èŸ²ç³»çµ± v5.0")
        print("=" * 70)
        
        try:
            print("ğŸŒ ã€æ­¥é©Ÿ 1ã€‘æ­£åœ¨è¼‰å…¥æ´»å‹•åˆ—è¡¨é é¢...")
            
            # === ç¬¬ä¸€å±¤ï¼šæŠ“å–æ‰€æœ‰æ´»å‹•ç¶²å€ ===
            activity_urls = self.scrape_activity_list_enhanced()
            
            if not activity_urls:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ´»å‹•ç¶²å€ï¼Œç¨‹å¼çµæŸ")
                return
            
            print(f"\nğŸ“Š æ‰¾åˆ° {len(activity_urls)} å€‹æ´»å‹•ï¼Œæº–å‚™é–‹å§‹é€ä¸€çˆ¬å–")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰å·²çˆ¬å–çš„è³‡æ–™
            existing_count = len(self.current_data['events'])
            if existing_count > 0:
                print(f"ğŸ“‚ ç™¼ç¾å·²å­˜åœ¨ {existing_count} ç­†è³‡æ–™ï¼Œå°‡é€²è¡Œå¢é‡çˆ¬å–")
            
            # === ç¬¬äºŒå±¤ï¼šè¿´åœˆé»å…¥æŠ“å–è©³ç´°è³‡è¨Š ===
            print(f"\nğŸ”„ ã€ç¬¬äºŒå±¤ã€‘é–‹å§‹è¿´åœˆçˆ¬å–è©³ç´°è³‡è¨Š...")
            print("=" * 70)
            
            success_count = 0
            fail_count = 0
            skip_count = 0
            
            for idx, url in enumerate(activity_urls, 1):
                try:
                    # æª¢æŸ¥æ˜¯å¦å·²ç¶“çˆ¬å–é
                    existing_urls = [event['url'] for event in self.current_data['events']]
                    if url in existing_urls:
                        print(f"â­ï¸  ç¬¬ {idx} å€‹æ´»å‹•å·²å­˜åœ¨ï¼Œè·³é: {url}")
                        skip_count += 1
                        continue
                    
                    # çˆ¬å–å–®å€‹æ´»å‹•è³‡è¨Š
                    success = self.scrape_single_event_ultimate(url, idx)
                    if success:
                        success_count += 1
                    else:
                        fail_count += 1
                        
                    # æ¯çˆ¬å–5å€‹æ´»å‹•å¾ŒçŸ­æš«ä¼‘æ¯
                    if idx % 5 == 0:
                        print(f"\nâ³ å·²è™•ç† {idx} å€‹æ´»å‹•ï¼Œä¼‘æ¯ 2 ç§’...")
                        sleep(2)
                        
                except KeyboardInterrupt:
                    print(f"\nâš ï¸ ä½¿ç”¨è€…ä¸­æ–·ç¨‹å¼")
                    break
                except Exception as e:
                    print(f"âŒ è™•ç†ç¬¬ {idx} å€‹æ´»å‹•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    fail_count += 1
                    continue
            
            # === å®Œæˆçµ±è¨ˆ ===
            total_processed = success_count + fail_count
            total_in_db = len(self.current_data['events'])
            
            print("\n" + "=" * 70)
            print("ğŸ‰ Tixcraft çµ‚æ¥µçˆ¬èŸ²ç³»çµ±åŸ·è¡Œå®Œæˆï¼")
            print("=" * 70)
            print(f"ğŸ“Š æœ¬æ¬¡çˆ¬å–çµ±è¨ˆï¼š")
            print(f"   âœ… æˆåŠŸçˆ¬å–ï¼š{success_count} å€‹æ´»å‹•")
            print(f"   âŒ å¤±æ•—è·³éï¼š{fail_count} å€‹æ´»å‹•")
            print(f"   â­ï¸  é‡è¤‡è·³éï¼š{skip_count} å€‹æ´»å‹•")
            print(f"   ğŸ“‹ æœ¬æ¬¡è™•ç†ï¼š{total_processed} å€‹æ´»å‹•")
            if total_processed > 0:
                print(f"   ğŸ“ˆ æˆåŠŸç‡ï¼š{(success_count/total_processed*100):.1f}%")
            
            print(f"\nğŸ’¾ è³‡æ–™åº«çµ±è¨ˆï¼š")
            print(f"   ğŸ“ æª”æ¡ˆåç¨±ï¼š{self.json_filename}")
            print(f"   ğŸ“‹ ç¸½æ´»å‹•æ•¸ï¼š{total_in_db} å€‹")
            print(f"   ğŸ• æœ€å¾Œæ›´æ–°ï¼š{self.current_data.get('last_update', 'N/A')}")
            
            # è¨ˆç®—å„æ¬„ä½çš„æœ‰æ•ˆè³‡æ–™æ•¸é‡
            if total_in_db > 0:
                valid_titles = sum(1 for e in self.current_data['events'] if e.get('title', '') != 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜')
                valid_datetime = sum(1 for e in self.current_data['events'] if e.get('event_datetime', '') != 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜')
                valid_sale = sum(1 for e in self.current_data['events'] if e.get('sale_info', '') != 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜')
                valid_locations = sum(1 for e in self.current_data['events'] if e.get('location', '') != 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜')
                valid_prices = sum(1 for e in self.current_data['events'] if e.get('price', '') != 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜')
                
                print(f"\nğŸ“ˆ è³‡æ–™å“è³ªçµ±è¨ˆï¼š")
                print(f"   ğŸ­ æœ‰æ¨™é¡Œçš„ï¼š{valid_titles} å€‹ ({(valid_titles/total_in_db*100):.1f}%)")
                print(f"   ğŸ—“ï¸ æœ‰æ´»å‹•æ™‚é–“ï¼š{valid_datetime} å€‹ ({(valid_datetime/total_in_db*100):.1f}%)")
                print(f"   ğŸŸï¸ æœ‰å”®ç¥¨è³‡è¨Šï¼š{valid_sale} å€‹ ({(valid_sale/total_in_db*100):.1f}%)")
                print(f"   ğŸ“ æœ‰åœ°é»çš„ï¼š{valid_locations} å€‹ ({(valid_locations/total_in_db*100):.1f}%)")
                print(f"   ğŸ’° æœ‰ç¥¨åƒ¹çš„ï¼š{valid_prices} å€‹ ({(valid_prices/total_in_db*100):.1f}%)")
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç¨‹å¼è¢«ä½¿ç”¨è€…ä¸­æ–·")
        except Exception as e:
            print(f"âŒ åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")
        finally:
            print(f"\nğŸ”š ç¨‹å¼åŸ·è¡Œå®Œæˆ")
            print("=" * 70)
            input("æŒ‰ Enter éµé—œé–‰ç€è¦½å™¨ä¸¦çµæŸç¨‹å¼...")
            
            print("ğŸ”š æ­£åœ¨é—œé–‰ç€è¦½å™¨...")
            if hasattr(self, 'driver') and self.driver:
                self.driver.quit()
            print("âœ… ç€è¦½å™¨å·²é—œé–‰ï¼Œç¨‹å¼çµæŸ")


def main():
    """ä¸»ç¨‹å¼é€²å…¥é»"""
    print("\n" + "=" * 80)
    print("ğŸ§  Tixcraft çµ‚æ¥µçˆ¬èŸ²ç³»çµ± v5.0 - ç²¾ç¢ºåˆ†æµç‰ˆ")
    print("=" * 80)
    
    TARGET_URL = "https://tixcraft.com/activity"
    
    print(f"ğŸ¯ ç›®æ¨™ç¶²å€ï¼š{TARGET_URL}")
    print(f"ğŸ“… ç•¶å‰æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)
    
    print("\nğŸš€ ç³»çµ±åŠŸèƒ½ç‰¹è‰²ï¼š")
    print("ğŸ’¡ ç²¾ç¢ºã€Œè¡Œã€åˆ†æµï¼šé¿å…é‡è¤‡èˆ‡èª¤æŠ“")
    print("ğŸ” JSè¼‰å…¥å„ªåŒ–ï¼šWebDriverWaitç›£æ§dataLayer.artistName")
    print("ğŸ’¾ å³æ™‚å¯«å…¥ï¼šæ¯å€‹URLçˆ¬å®Œç«‹åˆ»ä¿å­˜ï¼Œæ”¯æ´æ–·é»çºŒçˆ¬")
    print("ğŸ¯ æ™ºèƒ½å ´é¤¨è¾¨è­˜ï¼šéæ¿¾æ–‡å®£ï¼Œä¿ç•™æ ¸å¿ƒåœ°é»è³‡è¨Š")
    print("ğŸ›¡ï¸ ä¸‰å±¤æ¨™é¡Œç­–ç•¥ï¼šJS â†’ HTML â†’ ä¿åº•ï¼Œçµ•ä¸å‡ºç¾ã€Œjså¤±æ•—ã€")
    print("ğŸ”„ å¢é‡çˆ¬å–ï¼šè‡ªå‹•è·³éå·²çˆ¬å–çš„æ´»å‹•")
    print("-" * 60)
    
    try:
        crawler = TixcraftUltimateCrawler(TARGET_URL)
        crawler.run_ultimate_crawl()
    except Exception as e:
        print(f"\nâŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")
        print("ç¨‹å¼ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤")
    finally:
        print("\n" + "=" * 80)
        print("ğŸ”š ç¨‹å¼åŸ·è¡ŒçµæŸ")
        print("=" * 80)
        input("\næŒ‰ Enter éµé—œé–‰è¦–çª—...")


if __name__ == "__main__":
    main()