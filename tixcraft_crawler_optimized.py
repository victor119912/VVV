#!/usr/bin/env python3
"""
Tixcraft æ™ºèƒ½çˆ¬èŸ²ç³»çµ±ï¼ˆå„ªåŒ–ç‰ˆ v4.0ï¼‰
ä½œè€…: Assistant
æ—¥æœŸ: 2026-02-25
åŠŸèƒ½: 
- ç¬¬ä¸€å±¤ï¼šæŠ“å–æ‰€æœ‰æ´»å‹•ç¶²å€ (ä½¿ç”¨ div.thumbnails a)
- ç¬¬äºŒå±¤ï¼šé€ä¸€é»å…¥çˆ¬å–è©³ç´°è³‡è¨Š (ID: synopsisEventTitle, intro)
- æ™ºèƒ½è³‡æ–™åˆ†é¡ï¼šä½¿ç”¨æ­£å‰‡è¡¨é”å¼é€²è¡Œé—œéµå­—éæ¿¾
- å¤šå…ƒHTMLå®šä½ï¼šintro + pæ¨™ç±¤å‚™ç”¨æŠ“å–
- è³‡æ–™æ¸…æ´—ï¼šç§»é™¤é‡è¤‡æ›è¡Œèˆ‡å¤šé¤˜ç©ºæ ¼
- é˜²åµæ¸¬ï¼šä¿ç•™å®Œæ•´çš„ååµæ¸¬æ©Ÿåˆ¶
- ç©©å®šæ€§ï¼šå®Œæ•´çš„ try-except éŒ¯èª¤è™•ç†
"""

from time import sleep
from datetime import datetime
import json
import re
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager


class TixcraftScraperOptimized:
    """Tixcraft æ¼”å‡ºè³‡è¨Šçˆ¬å–å™¨ï¼ˆæ™ºèƒ½ç‰ˆï¼‰"""
    
    def __init__(self, base_url="https://tixcraft.com/activity"):
        self.base_url = base_url
        self.driver = self._setup_driver()
        self.events_data = []  # å„²å­˜æ‰€æœ‰çˆ¬å–çš„è³‡æ–™
    
    def clean_text(self, text):
        """æ¸…ç†æ–‡å­—ï¼šç§»é™¤å¤šé¤˜ç©ºæ ¼ã€æ›è¡Œç¬¦è™Ÿã€ç‰¹æ®Šå­—ç¬¦"""
        if not text:
            return ""
        
        # ç§»é™¤å¤šé¤˜ç©ºæ ¼å’Œæ›è¡Œç¬¦è™Ÿ
        cleaned = re.sub(r'\s+', ' ', text.strip())
        
        # ç§»é™¤å¤šé¤˜çš„æ¨™é»ç¬¦è™Ÿé‡è¤‡
        cleaned = re.sub(r'[;,ï¼Œï¼›]{2,}', ';', cleaned)
        
        # ç§»é™¤é–‹é ­çµå°¾çš„åˆ†è™Ÿæˆ–é€—è™Ÿ
        cleaned = re.sub(r'^[;,ï¼Œï¼›\s]+|[;,ï¼Œï¼›\s]+$', '', cleaned)
        
        return cleaned.strip()
    
    def classify_event_info(self, text_content):
        """æ™ºèƒ½åˆ†é¡æ´»å‹•è³‡è¨Šï¼šä½¿ç”¨æ­£å‰‡è¡¨é”å¼é€²è¡Œé—œéµå­—éæ¿¾"""
        
        if not text_content:
            return {
                'date': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
                'time': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
                'location': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
                'price': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
                'sale_time': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜'
            }
        
        # åˆ†è¡Œè™•ç†
        lines = [line.strip() for line in text_content.split('\n') if line.strip()]
        
        # è³‡æ–™åˆ†é¡å®¹å™¨
        date_info = []
        time_info = []
        location_info = []
        price_info = []
        sale_time_info = []
        
        print(f"\nğŸ” ã€æ™ºèƒ½åˆ†é¡ã€‘æ­£åœ¨åˆ†æ {len(lines)} è¡Œå…§å®¹...")
        
        for line in lines:
            line = self.clean_text(line)
            if not line or len(line) < 3:  # å¿½ç•¥éçŸ­çš„è¡Œ
                continue
            
            # === æ—¥æœŸè³‡è¨Šåˆ†é¡ ===
            date_patterns = [
                r'æ¼”å‡ºæ—¥æœŸ[ï¼š:\s]*',
                r'æ´»å‹•æ—¥æœŸ[ï¼š:\s]*',
                r'æ—¥æœŸ[ï¼š:\s]*',
                r'Date[ï¼š:\s]*',
                r'æ™‚é–“[ï¼š:\s]*.*?202[0-9]',  # åŒ…å«å¹´ä»½çš„æ™‚é–“
                r'202[0-9]/\d+/\d+',  # æ—¥æœŸæ ¼å¼ 2026/01/01
                r'\d+æœˆ\d+æ—¥',  # ä¸­æ–‡æ—¥æœŸæ ¼å¼
                r'\d+/\d+\s*\([\u4e00-\u9fffæ—¥æœˆç«æ°´æœ¨é‡‘åœŸ]\)',  # æ—¥æœŸ+æ˜ŸæœŸ
            ]
            
            if any(re.search(pattern, line, re.IGNORECASE) for pattern in date_patterns):
                # é¿å…ç¥¨åƒ¹è¢«èª¤åˆ¤ç‚ºæ—¥æœŸ
                if not re.search(r'NT\$|å…ƒ|åƒ¹æ ¼|ç¥¨åƒ¹|PRICE', line, re.IGNORECASE):
                    date_info.append(line)
                    continue
            
            # === åœ°é»è³‡è¨Šåˆ†é¡ ===
            location_patterns = [
                r'æ¼”å‡ºåœ°é»[ï¼š:\s]*',
                r'åœ°é»[ï¼š:\s]*',
                r'å ´åœ°[ï¼š:\s]*',
                r'æœƒå ´[ï¼š:\s]*',
                r'Venue[ï¼š:\s]*',
                r'æ¼”å‡ºå ´æ‰€[ï¼š:\s]*',
                r'.*?é¤¨$',  # ä»¥é¤¨çµå°¾
                r'.*?å»³$',  # ä»¥å»³çµå°¾
                r'.*?é™¢$',  # ä»¥é™¢çµå°¾
                r'.*?ä¸­å¿ƒ$',  # ä»¥ä¸­å¿ƒçµå°¾
                r'.*?é«”è‚²å ´$|.*?å·¨è›‹$|.*?Arena$',  # é«”è‚²å ´é¤¨
            ]
            
            if any(re.search(pattern, line, re.IGNORECASE) for pattern in location_patterns):
                # é¿å…å…¶ä»–è³‡è¨Šè¢«èª¤åˆ¤
                if not re.search(r'NT\$|å…ƒ|åƒ¹æ ¼|ç¥¨åƒ¹|æ™‚é–“|202[0-9]|PRICE', line, re.IGNORECASE):
                    location_info.append(line)
                    continue
            
            # === ç¥¨åƒ¹è³‡è¨Šåˆ†é¡ (å¼·åŒ–ç‰ˆ) ===
            price_patterns = [
                r'ç¥¨åƒ¹[ï¼š:\s]*',
                r'æ´»å‹•ç¥¨åƒ¹[ï¼š:\s]*',
                r'æ¼”å‡ºç¥¨åƒ¹[ï¼š:\s]*',  
                r'Price[ï¼š:\s]*',
                r'NT\$\s*\d+',  # NT$æ•¸å­—
                r'\d+\s*å…ƒ',  # æ•¸å­—+å…ƒ
                r'VIP.*?\$\d+|VVIP.*?\$\d+',  # VIPç¥¨åƒ¹
                r'\$\d+[\s/]*',  # $æ•¸å­—
                r'é–€ç¥¨[ï¼š:\s]*.*?\d+',  # é–€ç¥¨+æ•¸å­—
                r'å”®åƒ¹[ï¼š:\s]*',
                r'ç¥¨åˆ¸[ï¼š:\s]*',
                r'\d+(?:,\d{3})*å…ƒ',  # åƒåˆ†ä½æ•¸å­—+å…ƒ (å¦‚: 1,200å…ƒ)
                r'å…¨ç¥¨.*?\d+|åŠç¥¨.*?\d+',  # å…¨ç¥¨/åŠç¥¨
            ]
            
            if any(re.search(pattern, line, re.IGNORECASE) for pattern in price_patterns):
                # é€²ä¸€æ­¥ç¢ºèªæ˜¯ç¥¨åƒ¹ç›¸é—œï¼Œä½†æ’é™¤æ—¥æœŸæ™‚é–“
                if re.search(r'NT\$|\d+å…ƒ|\$\d+|åƒ¹æ ¼|ç¥¨åƒ¹|PRICE|VIP|èº«éšœ|å”®åƒ¹|ç¥¨åˆ¸', line, re.IGNORECASE):
                    if not re.search(r'202[0-9]|æœˆ|æ—¥|æ™‚|åˆ†|ï¼š\d{2}', line):  # æ’é™¤æ—¥æœŸæ™‚é–“
                        price_info.append(line)
                        continue
            
            # === å”®ç¥¨æ™‚é–“åˆ†é¡ (å¼·åŒ–ç‰ˆ) ===
            sale_patterns = [
                r'é–‹è³£[ï¼š:\s]*',
                r'å”®ç¥¨æ™‚é–“[ï¼š:\s]*',
                r'é å”®[ï¼š:\s]*',
                r'é–‹å”®[ï¼š:\s]*',
                r'å…¨é¢é–‹è³£[ï¼š:\s]*',
                r'é è³¼[ï¼š:\s]*',
                r'Sale[ï¼š:\s]*.*?202[0-9]',
                r'è³¼ç¥¨[ï¼š:\s]*.*?202[0-9]',
                r'ç™¼å”®[ï¼š:\s]*.*?202[0-9]',
                r'æœƒå“¡.*?202[0-9].*?é–‹è³£',
                r'ä¸€èˆ¬.*?202[0-9].*?é–‹è³£',
                r'\d+/\d+.*?é–‹è³£|é–‹è³£.*?\d+/\d+',  # åŒ…å«é–‹è³£çš„æ—¥æœŸæ ¼å¼
            ]
            
            if any(re.search(pattern, line, re.IGNORECASE) for pattern in sale_patterns):
                if re.search(r'202[0-9]|\d+æœˆ\d+æ—¥', line):  # å¿…é ˆåŒ…å«å¹´ä»½æˆ–ä¸­æ–‡æ—¥æœŸ
                    # æ’é™¤å–®ç´”çš„æ¼”å‡ºæ—¥æœŸ
                    if re.search(r'é–‹è³£|é å”®|å”®ç¥¨|é è³¼|è³¼ç¥¨|ç™¼å”®|Sale', line, re.IGNORECASE):
                        sale_time_info.append(line)
                        continue
            
            # === æ¼”å‡ºæ™‚é–“åˆ†é¡ (æ›´ç²¾ç¢º) ===
            time_patterns = [
                r'æ¼”å‡ºæ™‚é–“[ï¼š:\s]*.*?\d+:\d+',  # æ¼”å‡ºæ™‚é–“+æ™‚åˆ†
                r'é–‹æ¼”[ï¼š:\s]*.*?\d+:\d+',  # é–‹æ¼”+æ™‚åˆ†
                r'æ™‚é–“[ï¼š:\s]*.*?\d+:\d+',  # æ™‚é–“+æ™‚åˆ†ï¼Œä½†ä¸åŒ…å«å¹´ä»½
                r'\d+:\d+\s*(PM|AM)',  # æ™‚åˆ†+PM/AM
                r'\d+é»\d+åˆ†',  # ä¸­æ–‡æ™‚é–“æ ¼å¼
            ]
            
            if any(re.search(pattern, line, re.IGNORECASE) for pattern in time_patterns):
                # ç¢ºä¿ä¸æ˜¯åŒ…å«å¹´ä»½çš„æ—¥æœŸè³‡è¨Š
                if not re.search(r'202[0-9]|\d+æœˆ\d+æ—¥', line):
                    time_info.append(line)
                    continue
        
        # çµ„è£çµæœ
        result = {
            'date': '; '.join(date_info) if date_info else 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'time': '; '.join(time_info) if time_info else 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜', 
            'location': '; '.join(location_info) if location_info else 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'price': '; '.join(price_info) if price_info else 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'sale_time': '; '.join(sale_time_info) if sale_time_info else 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜'
        }
        
        # è¼¸å‡ºåˆ†é¡çµ±è¨ˆ
        print(f"   ğŸ“… æ—¥æœŸè³‡è¨Š: {len(date_info)} æ¢")
        print(f"   â° æ™‚é–“è³‡è¨Š: {len(time_info)} æ¢") 
        print(f"   ğŸ“ åœ°é»è³‡è¨Š: {len(location_info)} æ¢")
        print(f"   ğŸ’° ç¥¨åƒ¹è³‡è¨Š: {len(price_info)} æ¢")
        print(f"   ğŸŸï¸ å”®ç¥¨è³‡è¨Š: {len(sale_time_info)} æ¢")
        
        return result
    
    def get_data_from_js(self):
        """å¾JavaScript dataLayeræŠ“å–artistNameï¼ˆwith 10ç§’è¶…æ™‚æ©Ÿåˆ¶ï¼‰"""
        print("ğŸ” æ­£åœ¨å˜—è©¦å¾JavaScript dataLayeræå–æ¨™é¡Œ...")
        
        max_wait = 10  # æœ€å¤šç­‰å¾…10ç§’
        wait_count = 0
        
        while wait_count < max_wait:
            try:
                # æª¢æŸ¥ dataLayer æ˜¯å¦å­˜åœ¨ä¸”åŒ…å« artistName
                js_code = """
                if (typeof dataLayer !== 'undefined' && dataLayer.length > 0) {
                    for (let i = 0; i < dataLayer.length; i++) {
                        if (dataLayer[i].artistName) {
                            return dataLayer[i].artistName;
                        }
                    }
                }
                return null;
                """
                
                result = self.driver.execute_script(js_code)
                
                if result:
                    print(f"âœ… å¾ dataLayer æˆåŠŸæå–åˆ°æ¨™é¡Œ: {result}")
                    return result
                
                # å¦‚æœæ²’æœ‰æ‰¾åˆ° artistNameï¼Œç­‰å¾…1ç§’å¾Œé‡è©¦
                sleep(1)
                wait_count += 1
                print(f"â³ ç­‰å¾… dataLayer è¼‰å…¥... ({wait_count}/{max_wait}ç§’)")
                
            except Exception as e:
                print(f"âš ï¸ JSåŸ·è¡ŒéŒ¯èª¤: {e}ï¼Œ1ç§’å¾Œé‡è©¦...")
                sleep(1)
                wait_count += 1
        
        print(f"âŒ ç¶“é{max_wait}ç§’ç­‰å¾…ï¼Œæœªèƒ½å¾dataLayerç²å–æ¨™é¡Œ")
        return None
    
    def get_fallback_title(self):
        """ä¿åº•æ¨™é¡Œæå–ï¼šä½¿ç”¨ç¶²é æ¨™ç±¤title"""
        try:
            page_title = self.driver.title
            if page_title:
                # ä½¿ç”¨ split('-')[0] æå–æ¨™é¡Œçš„ç¬¬ä¸€éƒ¨åˆ†
                clean_title = page_title.split('-')[0].strip()
                if clean_title:
                    print(f"âœ… ä½¿ç”¨ç¶²é æ¨™ç±¤ä½œç‚ºä¿åº•æ¨™é¡Œ: {clean_title}")
                    return clean_title
            
            # å¦‚æœé€£ç¶²é æ¨™ç±¤éƒ½æ²’æœ‰ï¼Œä½¿ç”¨é è¨­æ–‡å­—
            print("âš ï¸ ç¶²é æ¨™ç±¤ç‚ºç©ºï¼Œä½¿ç”¨é è¨­æ¨™é¡Œ")
            return "è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜"
            
        except Exception as e:
            print(f"âŒ æå–ä¿åº•æ¨™é¡Œå¤±æ•—: {e}")
            return "è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜"
    
    def extract_alternative_content(self):
        """å‚™ç”¨è³‡æ–™æŠ“å–ï¼šå˜—è©¦å¾pæ¨™ç±¤æˆ–å…¶ä»–å…ƒç´ ç²å–è³‡è¨Š"""
        try:
            print("ğŸ”„ æ­£åœ¨å˜—è©¦å‚™ç”¨è³‡æ–™æŠ“å–æ–¹æ³•...")
            
            # æ–¹æ³•1: æŠ“å–æ‰€æœ‰pæ¨™ç±¤
            p_elements = self.driver.find_elements(By.TAG_NAME, "p")
            p_content = ""
            
            for p in p_elements:
                text = p.text.strip()
                if text and len(text) > 10:  # éæ¿¾å¤ªçŸ­çš„å…§å®¹
                    p_content += text + "\n"
            
            if p_content:
                print(f"âœ… å¾ {len(p_elements)} å€‹ p æ¨™ç±¤ä¸­æå–åˆ°å…§å®¹")
                return p_content
            
            # æ–¹æ³•2: æŠ“å–è¡¨æ ¼å…§å®¹
            table_elements = self.driver.find_elements(By.TAG_NAME, "table")
            table_content = ""
            
            for table in table_elements:
                text = table.text.strip()
                if text and len(text) > 10:
                    table_content += text + "\n"
            
            if table_content:
                print(f"âœ… å¾ {len(table_elements)} å€‹ table æ¨™ç±¤ä¸­æå–åˆ°å…§å®¹")
                return table_content
            
            # æ–¹æ³•3: æŠ“å–div.descriptionæˆ–é¡ä¼¼å®¹å™¨
            div_selectors = [
                "div.description", "div.content", "div.detail", 
                "div.info", ".event-info", ".activity-detail"
            ]
            
            for selector in div_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    for element in elements:
                        text = element.text.strip()
                        if text and len(text) > 20:
                            print(f"âœ… å¾ {selector} ä¸­æå–åˆ°å…§å®¹")
                            return text
                except:
                    continue
            
            print("âš ï¸ å‚™ç”¨æŠ“å–æ–¹æ³•æœªæ‰¾åˆ°æœ‰æ•ˆå…§å®¹")
            return None
            
        except Exception as e:
            print(f"âŒ å‚™ç”¨æŠ“å–æ–¹æ³•å¤±æ•—: {e}")
            return None
    
    def _setup_driver(self):
        """é…ç½®ä¸¦åˆå§‹åŒ– Chrome ç€è¦½å™¨ï¼ˆé˜²åµæ¸¬ç‰ˆï¼‰"""
        print("\nğŸ”§ ã€ç€è¦½å™¨åˆå§‹åŒ–ã€‘æ­£åœ¨è¨­å®š Chrome ç€è¦½å™¨...")
        print("   âš™ï¸  é…ç½®é˜²åµæ¸¬é¸é …...")
        options = Options()
        
        # === é˜²åµæ¸¬æ ¸å¿ƒè¨­å®š ===
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument("--disable-blink-features=AutomationControlled")
        print("   âœ… é˜²åµæ¸¬é¸é …é…ç½®å®Œæˆ")
        
        # æ•ˆèƒ½èˆ‡ç©©å®šæ€§è¨­å®š
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage") 
        options.add_argument("--disable-gpu")
        print("   âš¡ æ•ˆèƒ½é¸é …é…ç½®å®Œæˆ")
        
        # å»ºç«‹Chromeç€è¦½å™¨å¯¦ä¾‹
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        
        # === é€²éšJavaScripté˜²åµæ¸¬è¨­å®š ===
        print("   ğŸ›¡ï¸  åŸ·è¡Œé€²éšé˜²åµæ¸¬JavaScript...")
        driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
            'source': '''
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                })
            '''
        })
        print("   âœ… JavaScripté˜²åµæ¸¬è¨­å®šå®Œæˆ")
        
        # è¨­å®šé è¨­è¦–çª—å¤§å°èˆ‡ä½ç½®
        driver.set_window_size(1920, 1080)
        print("   ğŸ–¥ï¸  ç€è¦½å™¨è¦–çª—è¨­å®šå®Œæˆ")
        
        return driver
    
    def scrape_activity_list(self):
        """ç¬¬ä¸€å±¤ï¼šæŠ“å–æ‰€æœ‰æ¼”å‡ºæ´»å‹•çš„ç¶²å€æ¸…å–®ï¼ˆä¿®æ­£ç‰ˆ - ç¢ºä¿æŠ“å–æ‰€æœ‰43å€‹æ´»å‹•ï¼‰"""
        
        try:
            print(f"\nğŸŒ æ­£åœ¨è¼‰å…¥æ‹“å…ƒå”®ç¥¨æ´»å‹•åˆ—è¡¨é é¢...")
            self.driver.get(self.base_url)
            sleep(8)  # å¢åŠ ç­‰å¾…æ™‚é–“ç¢ºä¿ JavaScript å‹•æ…‹å…§å®¹å®Œå…¨è¼‰å…¥
            print("âœ… é é¢è¼‰å…¥å®Œæˆ")
            
            # === å¤šé‡é¸æ“‡å™¨ç­–ç•¥ç¢ºä¿æŠ“å–æ‰€æœ‰æ´»å‹• ===
            print("\nğŸ” æ­£åœ¨æœå°‹æ¼”å‡ºæ´»å‹•é€£çµ (å¤šé‡ç­–ç•¥)...")
            
            activity_links = []
            
            # ç­–ç•¥1ï¼šæŒ‡å®šçš„ div.thumbnails a
            try:
                links = self.driver.find_elements(By.CSS_SELECTOR, "div.thumbnails a")
                if links:
                    activity_links.extend(links)
                    print(f"   ç­–ç•¥1 (div.thumbnails a): æ‰¾åˆ° {len(links)} å€‹é€£çµ")
            except Exception as e:
                print(f"   ç­–ç•¥1å¤±æ•—: {e}")
            
            # ç­–ç•¥2ï¼šæ‰€æœ‰åŒ…å« activity/detail çš„ a æ¨™ç±¤
            try:
                links = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='activity/detail']")
                if links:
                    activity_links.extend(links)
                    print(f"   ç­–ç•¥2 (a[href*='activity/detail']): æ‰¾åˆ° {len(links)} å€‹é€£çµ")
            except Exception as e:
                print(f"   ç­–ç•¥2å¤±æ•—: {e}")
            
            # ç­–ç•¥3ï¼šclassåŒ…å«thumbnailçš„å…ƒç´ å…§çš„aæ¨™ç±¤
            try:
                links = self.driver.find_elements(By.CSS_SELECTOR, "[class*='thumbnail'] a, [class*='thumb'] a")
                if links:
                    activity_links.extend(links)
                    print(f"   ç­–ç•¥3 ([class*='thumbnail'] a): æ‰¾åˆ° {len(links)} å€‹é€£çµ")
            except Exception as e:
                print(f"   ç­–ç•¥3å¤±æ•—: {e}")
            
            # ç­–ç•¥4ï¼šæ‰€æœ‰classåŒ…å«activityçš„aæ¨™ç±¤
            try:
                links = self.driver.find_elements(By.CSS_SELECTOR, "a[class*='activity'], [class*='activity'] a")
                if links:
                    activity_links.extend(links)
                    print(f"   ç­–ç•¥4 (activityç›¸é—œclass): æ‰¾åˆ° {len(links)} å€‹é€£çµ")
            except Exception as e:
                print(f"   ç­–ç•¥4å¤±æ•—: {e}")
            
            if not activity_links:
                print("âŒ æ‰€æœ‰ç­–ç•¥éƒ½æœªæ‰¾åˆ°ä»»ä½•æ¼”å‡ºé€£çµ")
                return []
            
            print(f"âœ… ç¸½å…±æ‰¾åˆ° {len(activity_links)} å€‹å€™é¸é€£çµ")
            
            # æå–å”¯ä¸€çš„é€£çµä¸¦éæ¿¾é‡è¤‡
            unique_urls = set()
            valid_links = []
            
            for link in activity_links:
                try:
                    url = link.get_attribute('href')
                    if url and ('activity/detail' in url or '/activity/' in url) and url not in unique_urls:
                        unique_urls.add(url)
                        valid_links.append(url)
                except Exception as e:
                    print(f"âŒ æå–é€£çµæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
            
            print(f"ğŸ“Š éæ¿¾é‡è¤‡å¾Œç²å¾—å”¯ä¸€é€£çµ {len(valid_links)} å€‹")
            
            if len(valid_links) < 30:  # å¦‚æœé€£çµæ•¸å¤ªå°‘ï¼Œå˜—è©¦æ›´å»£æ³›çš„æœå°‹
                print("âš ï¸ é€£çµæ•¸é‡åå°‘ï¼Œå˜—è©¦å»£æ³›æœå°‹...")
                try:
                    all_links = self.driver.find_elements(By.TAG_NAME, "a")
                    for link in all_links:
                        try:
                            url = link.get_attribute('href')
                            if url and ('/activity/' in url or 'tixcraft.com' in url) and 'detail' in url and url not in unique_urls:
                                unique_urls.add(url)
                                valid_links.append(url)
                        except:
                            continue
                    print(f"ğŸ“Š æ“´å±•æœå°‹å¾Œç²å¾—é€£çµ {len(valid_links)} å€‹")
                except Exception as e:
                    print(f"æ“´å±•æœå°‹å¤±æ•—: {e}")
            
            print(f"\nğŸ“‹ æ´»å‹•ç¶²å€æ¸…å–®ï¼š")
            for i, url in enumerate(valid_links, 1):
                print(f"   {i}. {url}")
            
            return valid_links
            
        except Exception as e:
            print(f"âŒ ç¬¬ä¸€å±¤çˆ¬å–éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return []
    
    def scrape_single_event_details(self, url, index):
        """ç¬¬äºŒå±¤ï¼šçˆ¬å–å–®å€‹æ¼”å‡ºçš„è©³ç´°è³‡è¨Šï¼ˆæ™ºèƒ½ç‰ˆï¼‰"""
        
        print(f"\nğŸ” === ç¬¬ {index} å€‹æ´»å‹• ===")
        print(f"ğŸŒ æ­£åœ¨é€²å…¥: {url}")
        
        # åˆå§‹åŒ–è³‡æ–™çµæ§‹
        event_data = {
            'index': index,
            'title': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'date': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'time': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜', 
            'location': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'price': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'sale_time': 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜',
            'url': url
        }
        
        try:
            # å‰å¾€æ¼”å‡ºè©³æƒ…é é¢  
            self.driver.get(url)
            sleep(2)  # é¿å…åˆ‡æ›é é¢å¤ªå¿«è¢«ç¶²ç«™é˜»æ“‹
            
            # === æ™ºèƒ½æ¨™é¡ŒæŠ“å– (å„ªå…ˆé †åº: JS > HTML > ä¿åº•) ===
            title_found = False
            
            # å„ªå…ˆ1: å˜—è©¦å¾ JavaScript dataLayer æå–
            try:
                js_title = self.get_data_from_js()
                if js_title:
                    event_data['title'] = self.clean_text(js_title)
                    title_found = True
                    print(f"ğŸ­ æ¼”å‡ºé …ç›®åç¨± (JS): {event_data['title']}")
            except Exception as e:
                print(f"âš ï¸ JSæ¨™é¡Œæå–å¤±æ•—: {e}")
            
            # å„ªå…ˆ2: å˜—è©¦å¾ HTML synopsisEventTitle æå–
            if not title_found:
                try:
                    title_element = self.driver.find_element(By.ID, "synopsisEventTitle")
                    if title_element.text and len(title_element.text.strip()) > 0:
                        event_data['title'] = self.clean_text(title_element.text)
                        title_found = True
                        print(f"ğŸ­ æ¼”å‡ºé …ç›®åç¨± (HTML): {event_data['title']}")
                except Exception as e:
                    print(f"âš ï¸ ç„¡æ³•æŠ“å–HTMLæ¨™é¡Œ: {e}")
            
            # ä¿åº•3: ä½¿ç”¨ç¶²é æ¨™ç±¤ä½œç‚ºæœ€å¾Œæ‰‹æ®µ
            if not title_found:
                event_data['title'] = self.get_fallback_title()
                print(f"ğŸ­ æ¼”å‡ºé …ç›®åç¨± (ä¿åº•): {event_data['title']}")
            
            # === æŠ“å–æ¼”å‡ºè©³ç´°è³‡è¨Š (ID: intro) ===
            content_found = False
            intro_text = ""
            
            try:
                intro_element = self.driver.find_element(By.ID, "intro")
                intro_text = intro_element.text.strip() if intro_element.text else ""
                
                if intro_text and len(intro_text) > 20:  # ç¢ºä¿å…§å®¹è¶³å¤ è±å¯Œ
                    content_found = True
                    print(f"âœ… å¾ intro å…ƒç´ æˆåŠŸæŠ“å–åˆ°å…§å®¹")
                else:
                    print(f"âš ï¸ intro å…ƒç´ å…§å®¹ä¸è¶³ï¼Œå˜—è©¦å‚™ç”¨æ–¹æ³•...")
                    
            except Exception as e:
                print(f"âš ï¸ ç„¡æ³•æŠ“å– intro å…ƒç´ : {e}")
            
            # === å¦‚æœintroä¸å¤ å®Œæ•´ï¼Œå˜—è©¦å‚™ç”¨æŠ“å–æ–¹æ³• ===
            if not content_found:
                alternative_content = self.extract_alternative_content()
                if alternative_content:
                    intro_text = alternative_content
                    content_found = True
                    print(f"âœ… å‚™ç”¨æ–¹æ³•æˆåŠŸç²å–å…§å®¹")
                else:
                    print(f"âŒ æ‰€æœ‰æŠ“å–æ–¹æ³•éƒ½ç„¡æ³•ç²å–è¶³å¤ å…§å®¹")
            
            # === æ™ºèƒ½åˆ†é¡è³‡æ–™ ===
            if content_found and intro_text:
                print(f"\nğŸ“‹ ã€å…§å®¹åˆ†æã€‘æ­£åœ¨é€²è¡Œæ™ºèƒ½åˆ†é¡...")
                print(f"ğŸ“ åŸå§‹å…§å®¹é•·åº¦: {len(intro_text)} å­—ç¬¦")
                
                # ä½¿ç”¨æ™ºèƒ½åˆ†é¡åŠŸèƒ½
                classified_info = self.classify_event_info(intro_text)
                
                # æ›´æ–°è³‡æ–™çµæ§‹ (é™¤äº†titleä»¥å¤–)
                for key in ['date', 'time', 'location', 'price', 'sale_time']:
                    event_data[key] = classified_info[key]
                
                # è¼¸å‡ºåˆ†é¡çµæœåˆ°çµ‚ç«¯æ©Ÿ
                print(f"\nğŸ“Š ã€åˆ†é¡çµæœã€‘")
                print("-" * 50)
                print(f"ğŸ“… æ¼”å‡ºæ—¥æœŸ: {event_data['date']}")
                print(f"â° æ¼”å‡ºæ™‚é–“: {event_data['time']}")
                print(f"ğŸ“ æ¼”å‡ºåœ°é»: {event_data['location']}")
                print(f"ğŸ’° æ´»å‹•ç¥¨åƒ¹: {event_data['price']}")
                print(f"ğŸŸï¸ å”®ç¥¨æ™‚é–“: {event_data['sale_time']}")
                
            else:
                print(f"\nğŸ“‹ âš ï¸ æœªèƒ½ç²å–è¶³å¤ çš„è©³ç´°è³‡è¨Š")
                print(f"ğŸ“… æ¼”å‡ºæ—¥æœŸ: è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜")
                print(f"â° æ¼”å‡ºæ™‚é–“: è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜")
                print(f"ğŸ“ æ¼”å‡ºåœ°é»: è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜")
                print(f"ğŸ’° æ´»å‹•ç¥¨åƒ¹: è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜")
                print(f"ğŸŸï¸ å”®ç¥¨æ™‚é–“: è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜")
            
            print(f"ğŸ”— æ´»å‹•ç¶²å€: {url}")
            print(f"âœ… ç¬¬ {index} å€‹æ´»å‹•æŠ“å–å®Œæˆ")
            
            # å°‡è³‡æ–™åŠ å…¥æ”¶é›†æ¸…å–®
            self.events_data.append(event_data)
            return True
            
        except Exception as e:
            print(f"âŒ ç¬¬ {index} å€‹æ´»å‹•æŠ“å–å¤±æ•—: {e}")
            print(f"â­ï¸  è·³éæ­¤æ´»å‹•ï¼Œç¹¼çºŒä¸‹ä¸€å€‹...")
            # å³ä½¿å¤±æ•—ä¹Ÿè¦è¨˜éŒ„åŸºæœ¬è³‡è¨Š
            self.events_data.append(event_data)
            return False
    
    def save_to_json(self, filename='tixcraft_activities_optimized.json'):
        """å°‡çˆ¬å–çš„è³‡æ–™å„²å­˜ç‚º JSON æª”æ¡ˆ"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump({
                    'scrape_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'total_events': len(self.events_data),
                    'events': self.events_data
                }, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ è³‡æ–™å·²å„²å­˜è‡³ {filename}")
            return True
        except Exception as e:
            print(f"\nâŒ å„²å­˜æª”æ¡ˆå¤±æ•—: {e}")
            return False
    
    def run(self):
        """åŸ·è¡Œæ™ºèƒ½åŒ–æ·±åº¦çˆ¬å–"""
        print("\nğŸŒŸ é–‹å§‹åŸ·è¡Œ Tixcraft æ™ºèƒ½çˆ¬èŸ²ç³»çµ±")
        print("=" * 60)
        
        try:
            print("ğŸŒ ã€æ­¥é©Ÿ 1ã€‘æ­£åœ¨è¼‰å…¥æ´»å‹•åˆ—è¡¨é é¢...")
            print(f"   ğŸ“ ç›®æ¨™ç¶²å€ï¼š{self.base_url}")
            self.driver.get(self.base_url)
            sleep(3)  # ç­‰å¾…é é¢å®Œå…¨è¼‰å…¥
            print("âœ… é é¢è¼‰å…¥æˆåŠŸï¼")
            
            # === ç¬¬ä¸€å±¤ï¼šæŠ“å–æ‰€æœ‰æ´»å‹•ç¶²å€ ===
            print("\nğŸ“‹ ã€ç¬¬ä¸€å±¤ã€‘æŠ“å–æ‰€æœ‰æ´»å‹•ç¶²å€...")
            activity_urls = self.scrape_activity_list()
            
            if not activity_urls:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ´»å‹•ç¶²å€ï¼Œç¨‹å¼çµæŸ")
                return
            
            # === ç¬¬äºŒå±¤ï¼šè¿´åœˆé»å…¥æŠ“å–è©³ç´°è³‡è¨Š ===
            print(f"\nğŸ”„ ã€ç¬¬äºŒå±¤ã€‘é–‹å§‹è¿´åœˆçˆ¬å– {len(activity_urls)} å€‹æ´»å‹•çš„è©³ç´°è³‡è¨Š...")
            print("=" * 60)
            
            success_count = 0
            fail_count = 0
            
            for idx, url in enumerate(activity_urls, 1):
                try:
                    # è‡ªå‹•é€²å…¥è©²æ´»å‹•é é¢ä¸¦æŠ“å–è©³ç´°è³‡è¨Š
                    success = self.scrape_single_event_details(url, idx)
                    if success:
                        success_count += 1
                    else:
                        fail_count += 1
                        
                except Exception as e:
                    print(f"âŒ è™•ç†ç¬¬ {idx} å€‹æ´»å‹•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    print(f"â­ï¸  è·³éæ­¤æ´»å‹•ï¼Œç¹¼çºŒä¸‹ä¸€å€‹...")
                    fail_count += 1
                    continue
            
            # === å®Œæˆçµ±è¨ˆ ===
            print("\n" + "=" * 60)
            print("ğŸ‰ æ‰€æœ‰æ´»å‹•è³‡è¨ŠæŠ“å–å®Œæˆï¼")
            print("=" * 60)
            print(f"ğŸ“Š æŠ“å–çµ±è¨ˆçµæœï¼š")
            print(f"   âœ… æˆåŠŸæŠ“å–ï¼š{success_count} å€‹æ´»å‹•")
            print(f"   âŒ å¤±æ•—è·³éï¼š{fail_count} å€‹æ´»å‹•")
            print(f"   ğŸ“‹ ç¸½è¨ˆè™•ç†ï¼š{len(activity_urls)} å€‹æ´»å‹•")
            print(f"   ğŸ“ˆ æˆåŠŸç‡ï¼š{(success_count/len(activity_urls)*100):.1f}%")
            
            # === JSON å„²å­˜éšæ®µ ===
            if self.events_data:
                print(f"\nğŸ’¾ ã€JSON å„²å­˜ã€‘æ­£åœ¨å„²å­˜è³‡æ–™...")
                success = self.save_to_json()
                if success:
                    print(f"ğŸ“Š JSON å„²å­˜çµæœï¼š")
                    print(f"   ğŸ“ æª”æ¡ˆåç¨±ï¼štixcraft_activities_optimized.json")
                    print(f"   ğŸ“‹ ç¸½æ¼”å‡ºæ•¸ï¼š{len(self.events_data)} å€‹")
                    
                    # è¨ˆç®—å„æ¬„ä½çš„æœ‰æ•ˆè³‡æ–™æ•¸é‡
                    valid_titles = sum(1 for e in self.events_data if e['title'] != 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜')
                    valid_dates = sum(1 for e in self.events_data if e['date'] != 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜')
                    valid_times = sum(1 for e in self.events_data if e['time'] != 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜')
                    valid_locations = sum(1 for e in self.events_data if e['location'] != 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜')
                    valid_prices = sum(1 for e in self.events_data if e['price'] != 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜')
                    valid_sale_times = sum(1 for e in self.events_data if e['sale_time'] != 'è«‹åƒé–±å®˜ç¶²è©³ç´°èªªæ˜')
                    
                    print(f"   ğŸ­ æœ‰æ¨™é¡Œçš„ï¼š{valid_titles} å€‹ ({(valid_titles/len(self.events_data)*100):.1f}%)")
                    print(f"   ğŸ“… æœ‰æ—¥æœŸçš„ï¼š{valid_dates} å€‹ ({(valid_dates/len(self.events_data)*100):.1f}%)")
                    print(f"   â° æœ‰æ™‚é–“çš„ï¼š{valid_times} å€‹ ({(valid_times/len(self.events_data)*100):.1f}%)")
                    print(f"   ğŸ“ æœ‰åœ°é»çš„ï¼š{valid_locations} å€‹ ({(valid_locations/len(self.events_data)*100):.1f}%)")
                    print(f"   ğŸ’° æœ‰ç¥¨åƒ¹çš„ï¼š{valid_prices} å€‹ ({(valid_prices/len(self.events_data)*100):.1f}%)")
                    print(f"   ğŸŸï¸ æœ‰å”®ç¥¨æ™‚é–“ï¼š{valid_sale_times} å€‹ ({(valid_sale_times/len(self.events_data)*100):.1f}%)")
            else:
                print(f"\nâš ï¸ ç„¡è³‡æ–™å¯å„²å­˜ï¼Œè·³éJSONå„²å­˜")
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç¨‹å¼è¢«ä½¿ç”¨è€…ä¸­æ–·")
        except Exception as e:
            print(f"âŒ åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")
            print("\nç¨‹å¼ç™¼ç”ŸéŒ¯èª¤ï¼Œä½†ç€è¦½å™¨å°‡ä¿æŒé–‹å•Ÿä»¥ä¾›æª¢æŸ¥...")
        finally:
            print(f"\nğŸ”š ç¨‹å¼åŸ·è¡Œå®Œæˆ")
            print("=" * 60)
            input("æŒ‰ Enter éµé—œé–‰ç€è¦½å™¨ä¸¦çµæŸç¨‹å¼...")
            
            print("ğŸ”š æ­£åœ¨é—œé–‰ç€è¦½å™¨...")
            if hasattr(self, 'driver') and self.driver:
                self.driver.quit()
            print("âœ… ç€è¦½å™¨å·²é—œé–‰ï¼Œç¨‹å¼çµæŸ")


def main():
    """ä¸»ç¨‹å¼é€²å…¥é»"""
    print("\n" + "=" * 70)
    print("ğŸ§  Tixcraft æ™ºèƒ½çˆ¬èŸ²ç³»çµ± v4.0 (å„ªåŒ–ç‰ˆ)")
    print("=" * 70)
    
    # === è¨­å®šç›®æ¨™åƒæ•¸ ===
    TARGET_URL = "https://tixcraft.com/activity"
    
    print(f"ğŸ¯ ç›®æ¨™ç¶²å€ï¼š{TARGET_URL}")
    print(f"ğŸ“… ç•¶å‰æ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    
    print("\nğŸš€ å³å°‡å•Ÿå‹•æ™ºèƒ½åŒ–æ·±åº¦çˆ¬å–ç³»çµ±...")
    print("ğŸ’¡ åŠŸèƒ½ï¼šè‡ªå‹•æŠ“å–æ‰€æœ‰æ´»å‹•ç¶²å€ï¼Œé€ä¸€é»å…¥çˆ¬å–è©³ç´°è³‡è¨Š")
    print("ğŸ§  æ™ºèƒ½ï¼šä½¿ç”¨æ­£å‰‡è¡¨é”å¼é€²è¡Œé—œéµå­—éæ¿¾èˆ‡è³‡æ–™åˆ†é¡")
    print("ğŸ”„ å‚™ç”¨ï¼šintroç„¡æ•ˆæ™‚è‡ªå‹•å˜—è©¦pæ¨™ç±¤ç­‰å…¶ä»–HTMLå…ƒç´ ")
    print("ğŸ§¹ æ¸…æ´—ï¼šå»é™¤å¤šé¤˜ç©ºæ ¼ã€æ›è¡Œç¬¦è™Ÿï¼Œå„ªåŒ–è³‡æ–™å“è³ª")
    print("ğŸ›¡ï¸ ç‰¹è‰²ï¼šé˜²åµæ¸¬è¨­å®š + é€£çºŒéŒ¯èª¤è™•ç† + æ™ºèƒ½å®¹éŒ¯")
    print("ğŸ’¾ å„²å­˜ï¼šçµ‚ç«¯æ©Ÿå³æ™‚é¡¯ç¤º + JSONæª”æ¡ˆæ°¸ä¹…ä¿å­˜")
    print("-" * 50)
    
    try:
        # === åˆå§‹åŒ–ä¸¦åŸ·è¡Œçˆ¬å–å™¨ ===
        scraper = TixcraftScraperOptimized(TARGET_URL)
        scraper.run()
    except Exception as e:
        print(f"\nâŒ ä¸»ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")
        print("ç¨‹å¼ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤")
    finally:
        print("\n" + "=" * 70)
        print("ğŸ”š ç¨‹å¼åŸ·è¡ŒçµæŸ")
        print("=" * 70)
        input("\næŒ‰ Enter éµé—œé–‰è¦–çª—...")


if __name__ == "__main__":
    main()