import json
import re
import time
import random
import logging
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager

class TixcraftPrecisionFieldScraper:
    def __init__(self):
        self.setup_logging()
        self.driver = None
        
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('tixcraft_precision_field.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def load_existing_data(self, filename='tixcraft_activities.json'):
        """è¼‰å…¥ç¾æœ‰çš„JSONè³‡æ–™"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.logger.info(f"æˆåŠŸè¼‰å…¥ç¾æœ‰è³‡æ–™ï¼š{len(data.get('events', []))} å€‹æ´»å‹•")
                return data
        except FileNotFoundError:
            self.logger.info(f"æª”æ¡ˆ {filename} ä¸å­˜åœ¨ï¼Œå°‡å»ºç«‹æ–°æª”æ¡ˆ")
            return None
        except Exception as e:
            self.logger.error(f"è¼‰å…¥ç¾æœ‰è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return None
    
    def merge_data(self, existing_data, new_events):
        """åˆä½µæ–°èˆŠè³‡æ–™ï¼Œä»¥URLä½œç‚ºå”¯ä¸€è­˜åˆ¥ç¬¦å»é‡è¤‡"""
        if not existing_data:
            return new_events
            
        existing_events = existing_data.get('events', [])
        existing_urls = {event['url']: event for event in existing_events}
        
        # æ›´æ–°æˆ–æ–°å¢äº‹ä»¶
        updated_count = 0
        new_count = 0
        
        for new_event in new_events:
            url = new_event['url']
            if url in existing_urls:
                # æ›´æ–°ç¾æœ‰äº‹ä»¶ï¼ˆä¿ç•™ç´¢å¼•ä½†æ›´æ–°å…¶ä»–è³‡æ–™ï¼‰
                old_index = existing_urls[url].get('index', new_event['index'])
                new_event['index'] = old_index
                existing_urls[url] = new_event
                updated_count += 1
                self.logger.debug(f"æ›´æ–°æ´»å‹•ï¼š{new_event['title']}")
            else:
                # æ–°å¢äº‹ä»¶
                existing_urls[url] = new_event
                new_count += 1
                self.logger.debug(f"æ–°å¢æ´»å‹•ï¼š{new_event['title']}")
        
        # é‡æ–°æ’åºä¸¦åˆ†é…ç´¢å¼•
        merged_events = list(existing_urls.values())
        for i, event in enumerate(merged_events, 1):
            event['index'] = i
            
        self.logger.info(f"è³‡æ–™åˆä½µå®Œæˆï¼šæ›´æ–° {updated_count} å€‹æ´»å‹•ï¼Œæ–°å¢ {new_count} å€‹æ´»å‹•ï¼Œç¸½è¨ˆ {len(merged_events)} å€‹æ´»å‹•")
        return merged_events
        
    def get_random_user_agent(self):
        """éš¨æ©Ÿé¸æ“‡çœŸå¯¦çš„ User-Agent å­—ä¸²"""
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2.1 Safari/605.1.15',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'
        ]
        return random.choice(user_agents)
        
    def setup_driver(self):
        """è¨­ç½®Chromeç€è¦½å™¨é¸é … - å¼·åŒ–ç‰ˆååµæ¸¬åŠŸèƒ½"""
        chrome_options = Options()
        
        # é—œé–‰ Headless æ¨¡å¼ä»¥ä¾¿æ‰‹å‹•é©—è­‰
        # chrome_options.add_argument('--headless')
        
        # åŸºæœ¬ç©©å®šæ€§è¨­å®š
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1366,768')  # å¸¸è¦‹è§£æåº¦
        
        # å¼·åŒ–ç‰ˆ WebDriver ç‰¹å¾µéš±è—
        chrome_options.add_experimental_option("excludeSwitches", [
            "enable-automation",
            "enable-logging",
            "disable-extensions",
            "test-type",
            "disable-background-timer-throttling",
            "disable-renderer-backgrounding",
            "disable-backgrounding-occluded-windows"
        ])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # éš¨æ©Ÿ User-Agent
        user_agent = self.get_random_user_agent()
        chrome_options.add_argument(f'--user-agent={user_agent}')
        self.logger.info(f"ä½¿ç”¨ User-Agent: {user_agent}")
        
        # é€²éšååµæ¸¬è¨­å®š
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--no-first-run')
        chrome_options.add_argument('--disable-default-apps')
        chrome_options.add_argument('--disable-infobars')
        chrome_options.add_argument('--disable-notifications')
        chrome_options.add_argument('--disable-popup-blocking')
        
        # åŠ é€Ÿè¨­å®š - ç¦ç”¨åœ–ç‰‡å’Œå¤šåª’é«”ï¼ˆä¿ç•™JavaScriptç”¨æ–¼dataLayeræå–ï¼‰
        chrome_options.add_argument('--disable-images')
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_experimental_option('prefs', {
            'profile.managed_default_content_settings.images': 2,
            'profile.default_content_setting_values.media_stream': 2,
        })
        
        # æ¨¡æ“¬çœŸå¯¦ç€è¦½è¡Œç‚º
        chrome_options.add_argument('--start-maximized')
        chrome_options.add_experimental_option('prefs', {
            'profile.default_content_setting_values.notifications': 2,
            'profile.default_content_settings.popups': 0
        })
        
        try:
            service = ChromeService(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # åŸ·è¡Œå¼·åŒ–ç‰ˆååµæ¸¬è…³æœ¬
            self.driver.execute_cdp_cmd('Runtime.evaluate', {
                "expression": "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
            })
            
            # éš±è— Selenium æ¨™è­˜
            self.driver.execute_cdp_cmd('Runtime.evaluate', {
                "expression": "Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]})"
            })
            
            self.driver.execute_cdp_cmd('Runtime.evaluate', {
                "expression": "Object.defineProperty(navigator, 'languages', {get: () => ['zh-TW', 'zh', 'en']})"
            })
            
            self.driver.execute_cdp_cmd('Runtime.evaluate', {
                "expression": "window.chrome = { runtime: {} };"
            })
            
            self.logger.info("Chromeç€è¦½å™¨å·²æˆåŠŸå•Ÿå‹•ï¼ˆååµæ¸¬æ¨¡å¼ï¼‰")
        except Exception as e:
            self.logger.error(f"Chromeç€è¦½å™¨å•Ÿå‹•å¤±æ•—ï¼š{e}")
            raise
            
    def clean_text(self, text):
        """æ¸…æ´—å™¨ï¼šç§»é™¤ç‰¹æ®Šç¬¦è™Ÿå’Œé›œè³ª"""
        if not text:
            return ""
            
        # ç§»é™¤æŒ‡å®šçš„ç‰¹æ®Šç¬¦è™Ÿ
        symbols_to_remove = [';', '&nbsp;', 'â—', 'ğŸ‘‰', 'â€»', 'â˜…', 'â–²', 'â– ', 'â—†', 'ğŸ«', 'ğŸ“', 'ğŸ’', 'â‹']
        
        for symbol in symbols_to_remove:
            text = text.replace(symbol, '')
        
        # ç§»é™¤å¤šé¤˜ç©ºç™½ä¸¦æ¸…ç†
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
        
    def get_clean_data_from_js(self, driver):
        """
        [æš´åŠ›å¼·åŒ–ç‰ˆ] å‹•æ…‹é‡è©¦ç›£æ§ JavaScript dataLayer æå–
        - æ¯éš”0.5ç§’é‡è©¦ï¼Œæœ€å¤šç­‰å¾…5ç§’
        - æ“´å¤§æœç´¢ç¯„åœï¼šéæ­·æ•´å€‹dataLayeré™£åˆ—
        - åªè¦å«æœ‰ artistNameã€gameCode æˆ– item_name å°±ç«‹åˆ»æå–
        """
        max_wait_time = 5.0  # æœ€å¤šç­‰å¾…5ç§’
        retry_interval = 0.5  # æ¯0.5ç§’é‡è©¦ä¸€æ¬¡
        attempt = 0
        start_time = time.time()
        
        self.logger.info("é–‹å§‹æš´åŠ›ç›£æ§ dataLayerï¼Œæœ€å¤šç­‰å¾…5ç§’...")
        
        while time.time() - start_time < max_wait_time:
            attempt += 1
            try:
                # æš´åŠ›æœç´¢æ•´å€‹ dataLayer é™£åˆ—çš„ JavaScript è…³æœ¬
                js_script = """
                // ç¢ºä¿ dataLayer å­˜åœ¨
                if (typeof dataLayer === 'undefined' || !Array.isArray(dataLayer)) {
                    return null;
                }
                
                // éæ­·æ•´å€‹ dataLayer é™£åˆ—ï¼Œæ“´å¤§æœç´¢ç¯„åœ
                for (let i = 0; i < dataLayer.length; i++) {
                    let item = dataLayer[i];
                    
                    // åªè¦åŒ…å«ä»¥ä¸‹ä»»ä¸€æ¬„ä½å°±ç«‹åˆ»æå–
                    if (item.artistName || item.gameCode || item.item_name) {
                        return {
                            found: true,
                            artistName: item.artistName || item.item_name || '',
                            gameCode: item.gameCode || '',
                            childCategoryName: item.childCategoryName || '',
                            promoter: item.promoter || '',
                            event: item.event || '',
                            venueInfo: item.venueInfo || item.venue || '',
                            location: item.location || '',
                            rawData: item
                        };
                    }
                }
                
                // å¦‚æœæ²’æ‰¾åˆ°ï¼Œè¿”å›æœç´¢ç‹€æ…‹
                return {found: false, dataLayerLength: dataLayer.length};
                """
                
                raw_info = driver.execute_script(js_script)
                
                if raw_info and raw_info.get('found'):
                    # æˆåŠŸæ‰¾åˆ°æ•¸æ“šï¼
                    result = {
                        "title": raw_info.get('artistName', 'æœªæŠ“åˆ°æ¨™é¡Œ'),
                        "category": raw_info.get('childCategoryName', 'æœªæŠ“åˆ°åˆ†é¡'),
                        "game_code": raw_info.get('gameCode', 'N/A'),
                        "promoter": raw_info.get('promoter', 'N/A'),
                        "venue_info": raw_info.get('venueInfo', ''),
                        "location": raw_info.get('location', '')
                    }
                    
                    self.logger.info(f"ğŸ¯ ç¬¬{attempt}æ¬¡å˜—è©¦æˆåŠŸï¼æ‰¾åˆ°dataLayeræ•¸æ“š: {result['title']}")
                    return result
                
                elif raw_info:
                    self.logger.debug(f"ç¬¬{attempt}æ¬¡å˜—è©¦ï¼šdataLayeré•·åº¦={raw_info.get('dataLayerLength', 0)}ï¼Œæœªæ‰¾åˆ°ç›®æ¨™æ•¸æ“š")
                else:
                    self.logger.debug(f"ç¬¬{attempt}æ¬¡å˜—è©¦ï¼šdataLayerä¸å­˜åœ¨æˆ–ç„¡æ³•è¨ªå•")
                
                # å¦‚æœæ²’æ‰¾åˆ°ï¼Œç­‰å¾…å¾Œé‡è©¦
                if time.time() - start_time < max_wait_time:
                    time.sleep(retry_interval)
                    
            except Exception as e:
                self.logger.debug(f"ç¬¬{attempt}æ¬¡JavaScriptåŸ·è¡Œå¤±æ•—: {e}")
                if time.time() - start_time < max_wait_time:
                    time.sleep(retry_interval)
        
        # è¶…æ™‚å¾Œè¿”å›ç©ºçµæœ
        self.logger.warning(f"æš´åŠ›ç›£æ§è¶…æ™‚({max_wait_time}ç§’)ï¼Œå…±å˜—è©¦{attempt}æ¬¡ï¼Œæœªæ‰¾åˆ°æœ‰æ•ˆdataLayeræ•¸æ“š")
        return {
            "title": "JSç›£æ§è¶…æ™‚", 
            "category": "æœªæŠ“åˆ°åˆ†é¡", 
            "game_code": "N/A", 
            "promoter": "N/A",
            "venue_info": "",
            "location": ""
        }
        
    def extract_event_info(self, lines):
        """ã€åˆä½µç‰ˆã€‘æ¼”å‡ºè³‡è¨Šæå– - çµ±ä¸€è™•ç†æ—¥æœŸæ™‚é–“è³‡è¨Š"""
        event_info_lines = []
        
        # æ“´å±•çš„æ—¥æœŸæ™‚é–“åŒ¹é…æ¨¡å¼
        datetime_patterns = [
            r'\d{4}/\d{1,2}/\d{1,2}',     # YYYY/MM/DD æ—¥æœŸæ ¼å¼
            r'\d{1,2}/\d{1,2}/\d{4}',     # MM/DD/YYYY æ—¥æœŸæ ¼å¼  
            r'\d{1,2}/\d{1,2}',          # MM/DD ç°¡åŒ–æ—¥æœŸæ ¼å¼
            r'\d{4}-\d{1,2}-\d{1,2}',     # YYYY-MM-DD æ—¥æœŸæ ¼å¼
            r'\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥', # YYYYå¹´MMæœˆDDæ—¥ ä¸­æ–‡æ—¥æœŸæ ¼å¼
            r'\d{1,2}æœˆ\d{1,2}æ—¥',        # MMæœˆDDæ—¥ ä¸­æ–‡ç°¡åŒ–æ ¼å¼
            r'\d{1,2}:\d{2}',           # HH:MM æ™‚é–“æ ¼å¼
            r'\d{1,2}ï¼š\d{2}'           # HHï¼šMM ä¸­æ–‡å†’è™Ÿæ™‚é–“æ ¼å¼
        ]
        
        # ç›¸é—œé—œéµå­—ï¼ˆæ¼”å‡ºè³‡è¨Šç›¸é—œï¼‰
        event_keywords = [
            'æ¼”å‡ºæ—¥æœŸ', 'æ´»å‹•æ—¥æœŸ', 'èˆ‰è¾¦æ—¥æœŸ', 'è¡¨æ¼”æ—¥æœŸ', 'é–‹æ¼”æ—¥æœŸ',
            'æ¼”å‡ºæ™‚é–“', 'é–‹æ¼”æ™‚é–“', 'è¡¨æ¼”æ™‚é–“', 'æ´»å‹•æ™‚é–“',
            'æ—¥æœŸ', 'æ™‚é–“', 'é–‹å§‹æ™‚é–“', 'æ´»å‹•è³‡è¨Š'
        ]
        
        for line in lines:
            # æ’é™¤å¹²æ“¾å…§å®¹
            if any(exclude in line for exclude in ['é€€ç¥¨', 'æ‰‹çºŒè²»', 'ibon', 'å®¢æœ', 'æ³¨æ„äº‹é …']):
                continue
                
            # æª¢æŸ¥æ˜¯å¦åŒ…å«æ—¥æœŸæ™‚é–“æ ¼å¼æˆ–ç›¸é—œé—œéµå­—
            has_datetime = any(re.search(pattern, line) for pattern in datetime_patterns)
            has_keyword = any(keyword in line for keyword in event_keywords)
            
            if has_datetime or has_keyword:
                clean_line = self.clean_text(line)
                if clean_line and clean_line not in event_info_lines:
                    event_info_lines.append(clean_line)
        
        # åˆä½µæ‰€æœ‰ç›¸é—œè³‡è¨Šï¼Œç”¨åˆ†è™Ÿåˆ†éš”
        if event_info_lines:
            return ' ; '.join(event_info_lines)
        
        return "æœªæ‰¾åˆ°"
        
    def extract_precise_price(self, lines):
        """æ´»å‹•ç¥¨åƒ¹æå– - æ”¾å¯¬è¦å‰‡ç‰ˆ"""
        for line in lines:
            # ç§»é™¤é•·åº¦é™åˆ¶ï¼Œæ”¹ç”¨ Regex æå–
            # å¿…é ˆåŒ…å« NT$ æˆ– å…ƒ
            price_matches = re.findall(r'NT\$\s?[\d,]+|[\d,]+å…ƒ', line)
            
            if price_matches:
                # æª¢æŸ¥æ˜¯å¦åŒ…å«ç¥¨åƒ¹ç›¸é—œé—œéµå­—
                price_keywords = ['ç¥¨åƒ¹', 'Price', 'NT$', 'å…ƒ', 'VIP', 'VVIP', 'Aå€', 'Bå€']
                if any(keyword in line for keyword in price_keywords):
                    return self.clean_text(line)
                    
        return "æœªæ‰¾åˆ°"
        
    def extract_precise_location(self, lines, js_data=None):
        """ã€ç²¾ç°¡ç‰ˆã€‘æ¼”å‡ºåœ°é»æå– - è‡ªå‹•æˆªæ–·å†—é•·å…§å®¹"""
        # å¦‚æœ JS çš„ dataLayer ç‰©ä»¶è£¡æœ‰å ´é¤¨è³‡è¨Šï¼Œå„ªå…ˆä½¿ç”¨
        if js_data:
            if js_data.get('venue_info') and js_data['venue_info'].strip():
                venue_info = self.clean_text(js_data['venue_info'])
                return self.simplify_location(venue_info)
            if js_data.get('location') and js_data['location'].strip():
                location = self.clean_text(js_data['location'])
                return self.simplify_location(location)
        
        # å ´é¤¨é—œéµå­—
        location_keywords = [
            'åœ°é»', 'Venue', 'é¤¨', 'é«”è‚²å ´', 'ä¸­å¿ƒ', 'Legacy', 'Zepp', 
            'æ¼”å‡ºåœ°é»', 'æ´»å‹•åœ°é»', 'èˆ‰è¾¦åœ°é»', 'å ´åœ°', 'Arena', 'å·¨è›‹',
            'éŸ³æ¨‚ä¸­å¿ƒ', 'å±•è¦½é¤¨', 'é«”è‚²é¤¨', 'æ¼”è—å»³', 'åŠ‡é™¢', 'éŸ³æ¨‚å»³',
            'å·¥å•†å±•è¦½', 'TICC', 'ATT', 'æµè¡ŒéŸ³æ¨‚', 'å°å·¨è›‹'
        ]
        
        for line in lines:
            if any(keyword in line for keyword in location_keywords):
                # å„ªå…ˆæ¬Šè™•ç†ï¼šå¦‚æœåŒæ™‚å‡ºç¾ã€Œåœ°é»ã€èˆ‡ã€Œæ³¨æ„äº‹é …ã€
                if 'åœ°é»' in line and 'æ³¨æ„äº‹é …' in line:
                    location_part = line.split('æ³¨æ„äº‹é …')[0]
                    clean_location = self.clean_text(location_part)
                    return self.simplify_location(clean_location)
                else:
                    clean_location = self.clean_text(line)
                    return self.simplify_location(clean_location)
        
        # JS å‚™æ´ï¼šå¦‚æœæ‰¾ä¸åˆ°åœ°é»ï¼Œå˜—è©¦å¾ä¸»è¾¦æ–¹æ‰¾ç·šç´¢
        if js_data and js_data.get('promoter') and js_data['promoter'] != 'N/A':
            promoter = js_data['promoter']
            if any(venue in promoter for venue in ['å°åŒ—', 'é«˜é›„', 'å°ä¸­', 'æ–°åŒ—']):
                return self.clean_text(f"ä¸»è¾¦æ–¹ç·šç´¢ï¼š{promoter}")
                    
        return "æœªæ‰¾åˆ°"
    
    def simplify_location(self, location_text):
        """ç²¾ç°¡åœ°é»è³‡è¨Š - è‡ªå‹•æˆªæ–·å†—é•·é€€ç¥¨è¦ç¯„"""
        if not location_text or location_text == "æœªæ‰¾åˆ°":
            return location_text
        
        # å¦‚æœå­—æ•¸è¶…é 50 å­—ï¼Œæª¢æŸ¥æ˜¯å¦åŒ…å«é€€ç¥¨è¦ç¯„ä¸¦è‡ªå‹•æˆªæ–·
        if len(location_text) > 50:
            # é€€ç¥¨è¦ç¯„é—œéµå­—
            refund_keywords = ['é€€ç¥¨', 'é€€æ›', 'æ‰‹çºŒè²»', 'è¦å®š', 'æ”¿ç­–', 'æ¢æ¬¾', 'èªªæ˜', 'æ³¨æ„äº‹é …', 'æé†’', 'é ˆçŸ¥']
            
            # å¦‚æœåŒ…å«é€€ç¥¨è¦ç¯„ï¼Œåœ¨ç¬¬ä¸€å€‹é€€ç¥¨é—œéµå­—å‰æˆªæ–·
            for keyword in refund_keywords:
                if keyword in location_text:
                    truncated = location_text.split(keyword)[0].strip()
                    if truncated:
                        self.logger.debug(f"åœ°é»è³‡è¨Šå·²æˆªæ–·ï¼š{len(location_text)} å­— â†’ {len(truncated)} å­—")
                        return truncated
                    break
            
            # å¦‚æœæ²’æœ‰é€€ç¥¨é—œéµå­—ä½†è¶…é 50 å­—ï¼Œç›´æ¥æˆªå–å‰ 50 å­—
            if len(location_text) > 50:
                truncated = location_text[:50] + "..."
                self.logger.debug(f"åœ°é»è³‡è¨Šå·²æˆªæ–·è‡³ 50 å­—ï¼š{truncated}")
                return truncated
        
        return location_text
        
    def extract_precise_sale_time(self, lines):
        """å”®ç¥¨æ™‚é–“ç¨ç«‹æå– - å°ˆé–€è™•ç†å”®ç¥¨è³‡è¨Š"""
        sale_keywords = ['å”®ç¥¨', 'é–‹è³£', 'å•Ÿå”®', 'é–‹å”®', 'è³¼ç¥¨', 'é å”®', 'æœƒå“¡è³¼']  # æ“´å±•å”®ç¥¨é—œéµå­—
        time_pattern = r'\d{1,2}:\d{2}'  # æ™‚é–“æ ¼å¼ HH:MM
        
        for line in lines:
            # æª¢æŸ¥æ˜¯å¦åŒ…å«å”®ç¥¨é—œéµå­— 
            if any(keyword in line for keyword in sale_keywords):
                # ç§»é™¤é•·åº¦é™åˆ¶ï¼Œåªè¦åŒ…å«å”®ç¥¨é—œéµå­—å°±ä¿ç•™
                return self.clean_text(line)
                
        return "æœªæ‰¾åˆ°"
        
    def extract_precise_time_backup(self, lines):
        """æ¼”å‡ºæ™‚é–“å‚™ç”¨æå– - å·²æ•´åˆè‡³ event_info"""
        show_keywords = ['æ¼”å‡º', 'é–‹æ¼”', 'è¡¨æ¼”']  
        time_pattern = r'\d{1,2}:\d{2}'
        
        for line in lines:
            if any(keyword in line for keyword in show_keywords) and re.search(time_pattern, line):
                return self.clean_text(line)
                    
        return "æœªæ‰¾åˆ°"
        
        
    def extract_all_text_from_intro(self, url):
        """å¾introå€å¡Šæå–æ‰€æœ‰æ–‡å­—è¡Œ"""
        try:
            self.driver.get(url)
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # æå–æ¨™é¡Œ
            title = "æœªæ‰¾åˆ°"
            try:
                title_element = self.driver.find_element(By.ID, "synopsisEventTitle")
                title = self.clean_text(title_element.text)
            except NoSuchElementException:
                try:
                    title_element = self.driver.find_element(By.TAG_NAME, "h1")
                    title = self.clean_text(title_element.text)
                except NoSuchElementException:
                    pass
            
            # æå–introå€å¡Šæ–‡å­—
            lines = []
            try:
                intro_element = self.driver.find_element(By.ID, "intro")
                all_text = intro_element.text
                
                # æŒ‰æ›è¡Œåˆ†å‰²æˆç¨ç«‹è¡Œ
                lines = [line.strip() for line in all_text.split('\n') if line.strip()]
                
            except NoSuchElementException:
                self.logger.warning(f"æœªæ‰¾åˆ°introå€å¡Šï¼š{url}")
                
            return title, lines
            
        except Exception as e:
            self.logger.error(f"æå–æ–‡å­—å¤±æ•— {url}: {e}")
            return "éŒ¯èª¤", []
            
    def process_single_event(self, url, index):
        """è™•ç†å–®ä¸€æ´»å‹•çš„å®Œæ•´é‚è¼¯ - å¼·åŒ–ç‰ˆ"""
        try:
            self.logger.info(f"è™•ç†æ´»å‹• {index}ï¼š{url}")
            
            # é€²å…¥é é¢ä¸¦ç­‰å¾…JavaScriptè¼‰å…¥
            self.driver.get(url)
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            time.sleep(random.uniform(3, 6))  # éš¨æ©Ÿç­‰å¾… 3-6 ç§’
            
            # å„ªå…ˆä½¿ç”¨ JavaScript dataLayer æå–ç²¾ç¢ºæ•¸æ“š
            js_data = self.get_clean_data_from_js(self.driver)
            
            # æå–HTMLåŸºæœ¬è³‡è¨Šä½œç‚ºå‚™ç”¨
            title, lines = self.extract_all_text_from_intro(url)
            
            # æ¨™é¡Œå¼·åˆ¶è£œå…¨ï¼šçµ•å°ä¸å…è¨±ã€æœªæ‰¾åˆ°ã€
            final_title = "æœªæ‰¾åˆ°"  # é è¨­å€¼
            
            # ç¬¬ä¸€å„ªå…ˆæ¬Šï¼šJSæ¨™é¡Œ
            if (js_data.get('title') and 
                js_data['title'] not in ['æœªæŠ“åˆ°æ¨™é¡Œ', 'JSæå–å¤±æ•—', 'JSç›£æ§è¶…æ™‚', ''] and 
                js_data['title'].strip()):
                final_title = js_data['title']
                self.logger.info(f"  [JSå„ªå…ˆ] ä½¿ç”¨æ¨™é¡Œ: {final_title}")
            # ç¬¬äºŒå„ªå…ˆæ¬Šï¼šHTMLæ¨™é¡Œ
            elif title and title not in ['æœªæ‰¾åˆ°', 'éŒ¯èª¤', ''] and title.strip():
                final_title = title
                self.logger.info(f"  [HTMLå‚™ç”¨] ä½¿ç”¨æ¨™é¡Œ: {final_title}")
            else:
                # å‚™æ´æ–¹æ¡ˆï¼šå¼·åˆ¶ä½¿ç”¨ç€è¦½å™¨åˆ†é æ¨™é¡Œ
                try:
                    browser_title = self.driver.title
                    if browser_title and browser_title.strip():
                        # æ¸…ç†ç€è¦½å™¨æ¨™é¡Œ
                        clean_browser_title = browser_title.replace('æ‹“å…ƒå”®ç¥¨ç¶²', '').replace('TIXCRAFT', '').strip()
                        if clean_browser_title:
                            final_title = clean_browser_title
                            self.logger.info(f"  [ç€è¦½å™¨å‚™æ´] ä½¿ç”¨æ¨™é¡Œ: {final_title}")
                        else:
                            # æœ€å¾Œå‚™æ´ï¼šå¾URLæå–æ´»å‹•ä»£ç¢¼ä½œç‚ºæ¨™é¡Œ
                            url_code = url.split('/')[-1] if '/' in url else 'unknown'
                            final_title = f"æ´»å‹•ä»£ç¢¼ï¼š{url_code}"
                            self.logger.info(f"  [URLæœ€çµ‚å‚™æ´] ä½¿ç”¨æ¨™é¡Œ: {final_title}")
                    else:
                        # æœ€å¾Œå‚™æ´ï¼šå¾URLæå–æ´»å‹•ä»£ç¢¼ä½œç‚ºæ¨™é¡Œ
                        url_code = url.split('/')[-1] if '/' in url else 'unknown'
                        final_title = f"æ´»å‹•ä»£ç¢¼ï¼š{url_code}"
                        self.logger.info(f"  [URLæœ€çµ‚å‚™æ´] ä½¿ç”¨æ¨™é¡Œ: {final_title}")
                except Exception as e:
                    # å¦‚æœé€£ç€è¦½å™¨æ¨™é¡Œéƒ½æŠ“ä¸åˆ°ï¼Œä½¿ç”¨URLä»£ç¢¼
                    url_code = url.split('/')[-1] if '/' in url else 'unknown'
                    final_title = f"æ´»å‹•ä»£ç¢¼ï¼š{url_code}"
                    self.logger.warning(f"  [ç•°å¸¸å‚™æ´] ç€è¦½å™¨æ¨™é¡Œæå–å¤±æ•—({e})ï¼Œä½¿ç”¨: {final_title}")
            
            if not lines:
                return {
                    'index': index,
                    'title': final_title,
                    'event_info': "æœªæ‰¾åˆ°",
                    'location': "æœªæ‰¾åˆ°",
                    'price': "æœªæ‰¾åˆ°",
                    'sale_time': "æœªæ‰¾åˆ°",
                    'url': url
                }
            
            # ä½¿ç”¨ç²¾ç¢ºæå–è¦å‰‡ï¼Œé˜²æ­¢ä½ç§»å•é¡Œ - ã€åˆä½µç‰ˆã€‘
            event_info = self.extract_event_info(lines)  # åˆä½µæ—¥æœŸæ™‚é–“è³‡è¨Š
            
            # ä¿®æ­£åœ°é»æå–ï¼Œå‚³å…¥ js_data
            location = self.extract_precise_location(lines, js_data)
            price = self.extract_precise_price(lines)
            sale_time = self.extract_precise_sale_time(lines)
            
            result = {
                'index': index,
                'title': final_title,
                'event_info': event_info,  # åˆä½µçš„æ¼”å‡ºè³‡è¨Š
                'location': location,
                'price': price,
                'sale_time': sale_time,
                'url': url
            }
            
            # æ—¥èªŒè¼¸å‡º - æ›´æ–°ç‚ºæ–°æ ¼å¼
            self.logger.info(f"  æ¨™é¡Œï¼š{final_title}")
            self.logger.info(f"  JSåˆ†é¡ï¼š{js_data.get('category', 'N/A')}")
            self.logger.info(f"  éŠæˆ²ä»£ç¢¼ï¼š{js_data.get('game_code', 'N/A')}")
            self.logger.info(f"  ä¸»è¾¦æ–¹ï¼š{js_data.get('promoter', 'N/A')}")
            self.logger.info(f"  æ¼”å‡ºè³‡è¨Šï¼š{event_info}")  # åˆä½µé¡¯ç¤º
            self.logger.info(f"  åœ°é»ï¼š{location}")
            self.logger.info(f"  ç¥¨åƒ¹ï¼š{price}")
            self.logger.info(f"  å”®ç¥¨æ™‚é–“ï¼š{sale_time}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"è™•ç†æ´»å‹•å¤±æ•— {url}: {e}")
            return {
                'index': index,
                'title': "éŒ¯èª¤",
                'event_info': "æå–å¤±æ•—",
                'location': "æå–å¤±æ•—",
                'price': "æå–å¤±æ•—", 
                'sale_time': "æå–å¤±æ•—",
                'url': url
            }
            
    def scrape_all_events(self):
        """çˆ¬å–æ‰€æœ‰æ´»å‹•ä¸¦è™•ç† - å³æ™‚å„²å­˜ç‰ˆ"""
        output_file = 'tixcraft_activities.json'
        
        try:
            self.setup_driver()
            
            # ç²å–æ´»å‹•åˆ—è¡¨
            base_url = "https://tixcraft.com/activity"
            self.driver.get(base_url)
            
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "div.thumbnails"))
            )
            
            # æ”¶é›†æ‰€æœ‰æ´»å‹•é€£çµ
            activity_links = []
            thumbnails = self.driver.find_elements(By.CSS_SELECTOR, "div.thumbnails a")
            
            for link in thumbnails:
                href = link.get_attribute('href')
                if href and 'activity/detail' in href:
                    activity_links.append(href)
                    
            total_activities = len(activity_links)
            self.logger.info(f"ğŸ¯ æ‰¾åˆ° {total_activities} å€‹æ´»å‹•ï¼Œé–‹å§‹å³æ™‚è™•ç†...")
            
            # å³æ™‚è™•ç†æ¯å€‹æ´»å‹•
            current_success_count = 0
            
            for index, url in enumerate(activity_links, 1):
                # è™•ç†å–®ä¸€æ´»å‹•
                event_data = self.process_single_event(url, index)
                
                if event_data['title'] not in ["éŒ¯èª¤", "æå–å¤±æ•—"]:
                    current_success_count += 1
                
                # ===== å³æ™‚å„²å­˜æ¨¡å¼ï¼šæ¯è™•ç†å®Œä¸€å€‹æ´»å‹•å°±ç«‹åˆ»å­˜æª” =====
                try:
                    # è®€å–ç¾æœ‰è³‡æ–™ï¼ˆæ¯æ¬¡éƒ½é‡æ–°è¼‰å…¥ç¢ºä¿æœ€æ–°ï¼‰
                    existing_data = self.load_existing_data(output_file)
                    
                    # åˆä½µæ–°èˆŠè³‡æ–™ï¼ˆå°‡ç•¶å‰è™•ç†çš„æ´»å‹•åŠ å…¥ï¼‰
                    current_events = [event_data]  # ç•¶å‰åªæœ‰ä¸€å€‹æ´»å‹•
                    merged_events = self.merge_data(existing_data, current_events)
                    
                    # é‡æ–°è¨ˆç®—çµ±è¨ˆè³‡æ–™ - æ›´æ–°ç‚ºæ–°æ¬„ä½çµæ§‹
                    merged_success_count = sum(1 for event in merged_events 
                                             if not all(field == "æœªæ‰¾åˆ°" for field in [
                                                 event.get('event_info', ''),  # æ›´æ–°ç‚ºåˆä½µæ¬„ä½
                                                 event.get('location', ''),
                                                 event.get('price', ''),
                                                 event.get('sale_time', '')
                                             ]))
                    merged_success_rate = (merged_success_count / len(merged_events)) * 100 if merged_events else 0
                    
                    # æº–å‚™å³æ™‚çµæœ
                    real_time_result = {
                        'scrape_time': time.strftime('%Y-%m-%d %H:%M:%S'),
                        'last_update': time.strftime('%Y-%m-%d %H:%M:%S'),
                        'total_events': len(merged_events),
                        'success_count': merged_success_count,
                        'success_rate': f'{merged_success_rate:.1f}%',
                        'extraction_method': 'realtime_precision_field_extraction',
                        'current_progress': f'{index}/{total_activities}',
                        'current_session_success': current_success_count,
                        'events': merged_events
                    }
                    
                    # å³æ™‚å¯«å…¥ JSON æª”æ¡ˆ
                    with open(output_file, 'w', encoding='utf-8') as f:
                        json.dump(real_time_result, f, ensure_ascii=False, indent=2)
                    
                    # å¢åŠ å®‰å…¨æ„Ÿï¼šæ¯æ¬¡å­˜æª”å¾Œåœ¨ Log ä¸­å°å‡ºé€²åº¦
                    self.logger.info(f"ğŸ’¾ å·²åŒæ­¥è‡³ JSON æª”æ¡ˆï¼Œç›®å‰é€²åº¦ï¼š{index}/{total_activities} ({index/total_activities*100:.1f}%)")
                    self.logger.info(f"ğŸ“Š æœ¬æ¬¡æˆåŠŸï¼š{current_success_count}ï¼Œæ•´é«”æˆåŠŸç‡ï¼š{merged_success_rate:.1f}%")
                    
                except Exception as save_error:
                    self.logger.error(f"âŒ å³æ™‚å­˜æª”å¤±æ•—: {save_error}")
                    # å³ä½¿å­˜æª”å¤±æ•—ä¹Ÿç¹¼çºŒè™•ç†ä¸‹ä¸€å€‹æ´»å‹•
                
                # éš¨æ©Ÿç­‰å¾…æ™‚é–“ï¼Œæ¨¡æ“¬çœŸå¯¦ç€è¦½è¡Œç‚º
                time.sleep(random.uniform(2, 4))
                
                # æ¯ 5 å€‹æ´»å‹•å°±ä¼‘æ¯ 8-12 ç§’
                if index % 5 == 0:
                    rest_time = random.uniform(8, 12)
                    self.logger.info(f"â¸ï¸  å·²è™•ç† {index} å€‹æ´»å‹•ï¼Œä¼‘æ¯ {rest_time:.1f} ç§’ä»¥é¿å…è¢«å°é–...")
                    time.sleep(rest_time)
            
            # æœ€çµ‚çµ±è¨ˆå’Œç¢ºèª
            final_data = self.load_existing_data(output_file)
            final_events = final_data.get('events', []) if final_data else []
            
            self.logger.info(f"ğŸ‰ æ‰€æœ‰æ´»å‹•è™•ç†å®Œæˆï¼")
            self.logger.info(f"ğŸ“ˆ æœ¬æ¬¡å·¥ä½œéšæ®µæˆåŠŸè™•ç†ï¼š{current_success_count}/{total_activities} å€‹æ´»å‹•")
            self.logger.info(f"ğŸ“‚ æœ€çµ‚è³‡æ–™åº«åŒ…å«ï¼š{len(final_events)} å€‹æ´»å‹•")
            self.logger.info(f"ğŸ’¾ å³æ™‚å„²å­˜å®Œæˆï¼š{output_file}")
            
            # è¿”å›æœ€çµ‚çµæœ
            return final_data if final_data else {
                'total_events': 0,
                'success_count': 0,
                'success_rate': '0.0%',
                'current_session_success': current_success_count,
                'events': []
            }
            
        except Exception as e:
            self.logger.error(f"âŒ çˆ¬å–éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return None
        finally:
            if self.driver:
                self.driver.quit()
                
def main():
    scraper = TixcraftPrecisionFieldScraper()
    result = scraper.scrape_all_events()
    
    if result:
        print(f"\n=== ğŸ¯ å³æ™‚å„²å­˜ç‰ˆè³‡æ–™æ›´æ–°çµæœ ===")
        print(f"æ›´æ–°æ™‚é–“ï¼š{result.get('last_update', 'N/A')}")
        print(f"è™•ç†é€²åº¦ï¼š{result.get('current_progress', 'N/A')}")
        print(f"æœ¬æ¬¡å·¥ä½œéšæ®µæˆåŠŸï¼š{result.get('current_session_success', 0)} å€‹")
        print(f"è³‡æ–™åº«ç¸½è¨ˆï¼š{result.get('total_events', 0)} å€‹æ´»å‹•")
        print(f"æ•´é«”æˆåŠŸç‡ï¼š{result.get('success_rate', '0.0%')}")
        print(f"æå–æ–¹æ³•ï¼š{result.get('extraction_method', 'realtime_precision_field_extraction')}")
        print(f"å„²å­˜æª”æ¡ˆï¼štixcraft_activities.json")
        
        # é¡¯ç¤ºæœ€è¿‘æ›´æ–°çš„5å€‹æ´»å‹•ç¤ºä¾‹
        events = result.get('events', [])
        if events:
            print(f"\n=== ğŸ” æœ€æ–°æ´»å‹•è³‡æ–™ç¤ºä¾‹ ===")
            recent_events = events[:5]  # å–å‰5å€‹ä½œç‚ºç¤ºä¾‹
            for i, event in enumerate(recent_events, 1):
                print(f"\nã€æ´»å‹• {i}ã€‘{event.get('title', 'N/A')}")
                print(f"  ğŸ“… æ¼”å‡ºè³‡è¨Šï¼š{event.get('event_info', 'N/A')}")  # åˆä½µé¡¯ç¤º
                print(f"  ğŸ“ åœ°é»ï¼š{event.get('location', 'N/A')}")
                print(f"  ğŸ’° ç¥¨åƒ¹ï¼š{event.get('price', 'N/A')}")
                print(f"  ğŸŸï¸ å”®ç¥¨æ™‚é–“ï¼š{event.get('sale_time', 'N/A')}")
        
        print(f"\nâœ… å³æ™‚å„²å­˜åŠŸèƒ½å·²å•Ÿç”¨ï¼")
        print(f"ğŸ’¾ æ¯è™•ç†ä¸€å€‹æ´»å‹•éƒ½æœƒç«‹åˆ»æ›´æ–° JSON æª”æ¡ˆ")
        print(f"ğŸ”„ è³‡æ–™å³æ™‚åŒæ­¥ï¼Œç„¡éœ€ç­‰å¾…å…¨éƒ¨å®Œæˆ")
        print(f"ğŸ“Š ç¸½å…±ç®¡ç† {result.get('total_events', 0)} å€‹æ´»å‹•è³‡æ–™")
        
    else:
        print("âŒ çˆ¬å–å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ—¥èªŒæ–‡ä»¶")

if __name__ == "__main__":
    main()