import json
import re
import time
import logging
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager

class TixcraftPrecisionFieldScraper:
    def __init__(self):
        self.setup_logging()
        self.driver = None
        
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('tixcraft_precision_field.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def load_existing_data(self, filename='tixcraft_activities.json'):
        """è¼‰å…¥ç¾æœ‰çš„JSONè³‡æ–™"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.logger.info(f"æˆåŠŸè¼‰å…¥ç¾æœ‰è³‡æ–™ï¼š{len(data.get('events', []))} å€‹æ´»å‹•")
                return data
        except FileNotFoundError:
            self.logger.info(f"æª”æ¡ˆ {filename} ä¸å­˜åœ¨ï¼Œå°‡å»ºç«‹æ–°æª”æ¡ˆ")
            return None
        except Exception as e:
            self.logger.error(f"è¼‰å…¥ç¾æœ‰è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return None
    
    def merge_data(self, existing_data, new_events):
        """åˆä½µæ–°èˆŠè³‡æ–™ï¼Œä»¥URLä½œç‚ºå”¯ä¸€è­˜åˆ¥ç¬¦å»é‡è¤‡"""
        if not existing_data:
            return new_events
            
        existing_events = existing_data.get('events', [])
        existing_urls = {event['url']: event for event in existing_events}
        
        # æ›´æ–°æˆ–æ–°å¢äº‹ä»¶
        updated_count = 0
        new_count = 0
        
        for new_event in new_events:
            url = new_event['url']
            if url in existing_urls:
                # æ›´æ–°ç¾æœ‰äº‹ä»¶ï¼ˆä¿ç•™ç´¢å¼•ä½†æ›´æ–°å…¶ä»–è³‡æ–™ï¼‰
                old_index = existing_urls[url].get('index', new_event['index'])
                new_event['index'] = old_index
                existing_urls[url] = new_event
                updated_count += 1
                self.logger.debug(f"æ›´æ–°æ´»å‹•ï¼š{new_event['title']}")
            else:
                # æ–°å¢äº‹ä»¶
                existing_urls[url] = new_event
                new_count += 1
                self.logger.debug(f"æ–°å¢æ´»å‹•ï¼š{new_event['title']}")
        
        # é‡æ–°æ’åºä¸¦åˆ†é…ç´¢å¼•
        merged_events = list(existing_urls.values())
        for i, event in enumerate(merged_events, 1):
            event['index'] = i
            
        self.logger.info(f"è³‡æ–™åˆä½µå®Œæˆï¼šæ›´æ–° {updated_count} å€‹æ´»å‹•ï¼Œæ–°å¢ {new_count} å€‹æ´»å‹•ï¼Œç¸½è¨ˆ {len(merged_events)} å€‹æ´»å‹•")
        return merged_events
        
    def setup_driver(self):
        """è¨­ç½®Chromeç€è¦½å™¨é¸é …"""
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        
        # ååµæ¸¬è¨­ç½®
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # è¨­ç½®ç”¨æˆ¶ä»£ç†
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        try:
            service = ChromeService(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # åŸ·è¡Œååµæ¸¬è…³æœ¬
            self.driver.execute_cdp_cmd('Runtime.evaluate', {
                "expression": "Object.defineProperty(navigator, 'webdriver', {get: () => undefined})"
            })
            
            self.logger.info("Chromeç€è¦½å™¨å·²æˆåŠŸå•Ÿå‹•")
        except Exception as e:
            self.logger.error(f"Chromeç€è¦½å™¨å•Ÿå‹•å¤±æ•—ï¼š{e}")
            raise
            
    def clean_text(self, text):
        """æ¸…æ´—å™¨ï¼šç§»é™¤ç‰¹æ®Šç¬¦è™Ÿå’Œé›œè³ª"""
        if not text:
            return ""
            
        # ç§»é™¤æŒ‡å®šçš„ç‰¹æ®Šç¬¦è™Ÿ
        symbols_to_remove = [';', '&nbsp;', 'â—', 'ğŸ‘‰', 'â€»', 'â˜…', 'â–²', 'â– ', 'â—†', 'ğŸ«', 'ğŸ“', 'ğŸ’', 'â‹']
        
        for symbol in symbols_to_remove:
            text = text.replace(symbol, '')
        
        # ç§»é™¤å¤šé¤˜ç©ºç™½ä¸¦æ¸…ç†
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
        
    def get_clean_data_from_js(self, driver):
        """
        [æ ¸å¿ƒåŠŸèƒ½] åŸ·è¡Œ JavaScript å¾ dataLayer æå– 100% æº–ç¢ºçš„å¾Œå°åƒæ•¸
        """
        try:
            # é€™æ˜¯é‡å°æ‹“å…ƒ dataLayer çµæ§‹è¨­è¨ˆçš„ç²¾ç¢ºæå–é‚è¼¯
            js_script = """
            var data = dataLayer.find(item => item.artistName !== undefined) || 
                       dataLayer.find(item => item.event === 'EnterActivityDetail') || 
                       {};
            return data;
            """
            raw_info = driver.execute_script(js_script)
            
            if not raw_info:
                return {
                    "title": "æœªæŠ“åˆ°æ¨™é¡Œ", "category": "æœªæŠ“åˆ°åˆ†é¡", 
                    "game_code": "N/A", "promoter": "N/A"
                }

            return {
                "title": raw_info.get('artistName', 'æœªæŠ“åˆ°æ¨™é¡Œ'),
                "category": raw_info.get('childCategoryName', 'æœªæŠ“åˆ°åˆ†é¡'),
                "game_code": raw_info.get('gameCode', 'N/A'),
                "promoter": raw_info.get('promoter', 'N/A')
            }
        except Exception as e:
            self.logger.error(f"JavaScript æ•¸æ“šæå–å¤±æ•—: {e}")
            return {"title": "JSæå–å¤±æ•—", "category": "JSæå–å¤±æ•—", "game_code": "N/A", "promoter": "N/A"}
        
    def extract_precise_date(self, lines):
        """æ¼”å‡ºæ—¥æœŸç²¾ç¢ºåŒ–æå–"""
        for line in lines:
            # æ’é™¤åŒ…å«ç‰¹å®šé—œéµè©çš„è¡Œ
            if any(keyword in line for keyword in ['é€€ç¥¨', 'æ‰‹çºŒè²»', 'ibon']):
                continue
                
            # é•·åº¦é™åˆ¶ï¼šå°æ–¼100å­—
            if len(line) > 100:
                continue
                
            # æª¢æŸ¥æ˜¯å¦åŒ…å«æ—¥æœŸæ ¼å¼ YYYY/MM/DD æˆ– MM/DD
            date_patterns = [
                r'\d{4}/\d{1,2}/\d{1,2}',  # YYYY/MM/DD
                r'\d{1,2}/\d{1,2}',        # MM/DD
                r'\d{4}-\d{1,2}-\d{1,2}',  # YYYY-MM-DD
                r'æ¼”å‡ºæ—¥æœŸ',
                r'æ´»å‹•æ—¥æœŸ',
                r'èˆ‰è¾¦æ—¥æœŸ'
            ]
            
            if any(re.search(pattern, line) for pattern in date_patterns):
                return self.clean_text(line)
                
        return "æœªæ‰¾åˆ°"
        
    def extract_precise_price(self, lines):
        """æ´»å‹•ç¥¨åƒ¹åš´æ ¼åŒ–æå–"""
        for line in lines:
            # å­—æ•¸è¶…é200å­—å‰‡è·³éï¼ˆé€šå¸¸æ˜¯é€€ç¥¨é ˆçŸ¥ï¼‰
            if len(line) > 200:
                continue
                
            # å¿…é ˆåŒ…å« NT$ æˆ– å…ƒ
            price_matches = re.findall(r'NT\$\s?[\d,]+|[\d,]+å…ƒ', line)
            
            if price_matches:
                # æª¢æŸ¥æ˜¯å¦åŒ…å«ç¥¨åƒ¹ç›¸é—œé—œéµå­—
                price_keywords = ['ç¥¨åƒ¹', 'Price', 'NT$', 'å…ƒ']
                if any(keyword in line for keyword in price_keywords):
                    return self.clean_text(line)
                    
        return "æœªæ‰¾åˆ°"
        
    def extract_precise_location(self, lines):
        """æ¼”å‡ºåœ°é»é–å®šæå–"""
        location_keywords = ['åœ°é»', 'Venue', 'é¤¨', 'é«”è‚²å ´', 'ä¸­å¿ƒ', 'Legacy', 'Zepp', 'æ¼”å‡ºåœ°é»', 'æ´»å‹•åœ°é»']
        
        for line in lines:
            if any(keyword in line for keyword in location_keywords):
                # å„ªå…ˆæ¬Šè™•ç†ï¼šå¦‚æœåŒæ™‚å‡ºç¾ã€Œåœ°é»ã€èˆ‡ã€Œæ³¨æ„äº‹é …ã€
                if 'åœ°é»' in line and 'æ³¨æ„äº‹é …' in line:
                    # æå–åœ°é»å¾Œçš„å…§å®¹ï¼Œæˆªæ–·æ³¨æ„äº‹é …
                    location_part = line.split('æ³¨æ„äº‹é …')[0]
                    return self.clean_text(location_part)
                else:
                    return self.clean_text(line)
                    
        return "æœªæ‰¾åˆ°"
        
    def extract_precise_sale_time(self, lines):
        """å”®ç¥¨æ™‚é–“ç²¾ç¢ºæå–"""
        sale_keywords = ['é–‹è³£', 'å•Ÿå”®', 'ä¸­åˆ', 'ä¸‹åˆ', 'å”®ç¥¨æ™‚é–“', 'é–‹è³£æ™‚é–“']
        time_pattern = r'\d{1,2}:\d{2}'  # æ™‚é–“æ ¼å¼ HH:MM
        
        for line in lines:
            # æª¢æŸ¥æ˜¯å¦åŒ…å«å”®ç¥¨é—œéµå­—
            if any(keyword in line for keyword in sale_keywords):
                # æª¢æŸ¥æ˜¯å¦åŒ…å«æ™‚é–“æ ¼å¼
                if re.search(time_pattern, line):
                    return self.clean_text(line)
                    
        return "æœªæ‰¾åˆ°"
        
    def extract_precise_time(self, lines):
        """æ¼”å‡ºæ™‚é–“æå–"""
        time_keywords = ['æ¼”å‡ºæ™‚é–“', 'é–‹æ¼”æ™‚é–“', 'è¡¨æ¼”æ™‚é–“', 'æ™‚é–“']
        time_pattern = r'\d{1,2}:\d{2}'
        
        for line in lines:
            if any(keyword in line for keyword in time_keywords):
                if re.search(time_pattern, line):
                    return self.clean_text(line)
                    
        return "æœªæ‰¾åˆ°"
        
    def extract_all_text_from_intro(self, url):
        """å¾introå€å¡Šæå–æ‰€æœ‰æ–‡å­—è¡Œ"""
        try:
            self.driver.get(url)
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # æå–æ¨™é¡Œ
            title = "æœªæ‰¾åˆ°"
            try:
                title_element = self.driver.find_element(By.ID, "synopsisEventTitle")
                title = self.clean_text(title_element.text)
            except NoSuchElementException:
                try:
                    title_element = self.driver.find_element(By.TAG_NAME, "h1")
                    title = self.clean_text(title_element.text)
                except NoSuchElementException:
                    pass
            
            # æå–introå€å¡Šæ–‡å­—
            lines = []
            try:
                intro_element = self.driver.find_element(By.ID, "intro")
                all_text = intro_element.text
                
                # æŒ‰æ›è¡Œåˆ†å‰²æˆç¨ç«‹è¡Œ
                lines = [line.strip() for line in all_text.split('\n') if line.strip()]
                
            except NoSuchElementException:
                self.logger.warning(f"æœªæ‰¾åˆ°introå€å¡Šï¼š{url}")
                
            return title, lines
            
        except Exception as e:
            self.logger.error(f"æå–æ–‡å­—å¤±æ•— {url}: {e}")
            return "éŒ¯èª¤", []
            
    def process_single_event(self, url, index):
        """è™•ç†å–®ä¸€æ´»å‹•çš„å®Œæ•´é‚è¼¯"""
        try:
            self.logger.info(f"è™•ç†æ´»å‹• {index}ï¼š{url}")
            
            # é€²å…¥é é¢ä¸¦ç­‰å¾…JavaScriptè¼‰å…¥
            self.driver.get(url)
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            time.sleep(2)  # ç¢ºä¿ JS è¼‰å…¥å®Œæˆ
            
            # å„ªå…ˆä½¿ç”¨ JavaScript dataLayer æå–ç²¾ç¢ºæ•¸æ“š
            js_data = self.get_clean_data_from_js(self.driver)
            
            # æå–HTMLåŸºæœ¬è³‡è¨Šä½œç‚ºå‚™ç”¨
            title, lines = self.extract_all_text_from_intro(url)
            
            # æ±ºå®šæœ€çµ‚æ¨™é¡Œï¼šå„ªå…ˆä½¿ç”¨JSæ•¸æ“š
            final_title = title
            if js_data['title'] != 'æœªæŠ“åˆ°æ¨™é¡Œ' and js_data['title'] != 'JSæå–å¤±æ•—':
                final_title = js_data['title']
                self.logger.info(f"  [å„ªå…ˆ] ä½¿ç”¨JSæ¨™é¡Œ: {final_title}")
            else:
                self.logger.info(f"  [å‚™ç”¨] ä½¿ç”¨HTMLæ¨™é¡Œ: {final_title}")
            
            if not lines:
                return {
                    'index': index,
                    'title': final_title,
                    'js_title': js_data['title'],
                    'category': js_data['category'],
                    'game_code': js_data['game_code'],
                    'promoter': js_data['promoter'],
                    'date': "æœªæ‰¾åˆ°",
                    'time': "æœªæ‰¾åˆ°", 
                    'location': "æœªæ‰¾åˆ°",
                    'price': "æœªæ‰¾åˆ°",
                    'sale_time': "æœªæ‰¾åˆ°",
                    'url': url
                }
            
            # ä½¿ç”¨ç²¾ç¢ºæå–è¦å‰‡
            date = self.extract_precise_date(lines)
            time_info = self.extract_precise_time(lines)
            location = self.extract_precise_location(lines)
            price = self.extract_precise_price(lines)
            sale_time = self.extract_precise_sale_time(lines)
            
            result = {
                'index': index,
                'title': final_title,
                'js_title': js_data['title'],
                'category': js_data['category'],
                'game_code': js_data['game_code'],
                'promoter': js_data['promoter'],
                'date': date,
                'time': time_info,
                'location': location,
                'price': price,
                'sale_time': sale_time,
                'url': url
            }
            
            # æ—¥èªŒè¼¸å‡º
            self.logger.info(f"  æ¨™é¡Œï¼š{final_title}")
            self.logger.info(f"  JSåˆ†é¡ï¼š{js_data['category']}")
            self.logger.info(f"  éŠæˆ²ä»£ç¢¼ï¼š{js_data['game_code']}")
            self.logger.info(f"  ä¸»è¾¦æ–¹ï¼š{js_data['promoter']}")
            self.logger.info(f"  æ—¥æœŸï¼š{date}")
            self.logger.info(f"  æ™‚é–“ï¼š{time_info}")
            self.logger.info(f"  åœ°é»ï¼š{location}")
            self.logger.info(f"  ç¥¨åƒ¹ï¼š{price}")
            self.logger.info(f"  å”®ç¥¨æ™‚é–“ï¼š{sale_time}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"è™•ç†æ´»å‹•å¤±æ•— {url}: {e}")
            return {
                'index': index,
                'title': "éŒ¯èª¤",
                'js_title': "æå–å¤±æ•—",
                'category': "æå–å¤±æ•—",
                'game_code': "æå–å¤±æ•—",
                'promoter': "æå–å¤±æ•—",
                'date': "æå–å¤±æ•—",
                'time': "æå–å¤±æ•—",
                'location': "æå–å¤±æ•—",
                'price': "æå–å¤±æ•—", 
                'sale_time': "æå–å¤±æ•—",
                'url': url
            }
            
    def scrape_all_events(self):
        """çˆ¬å–æ‰€æœ‰æ´»å‹•ä¸¦è™•ç†"""
        try:
            self.setup_driver()
            
            # ç²å–æ´»å‹•åˆ—è¡¨
            base_url = "https://tixcraft.com/activity"
            self.driver.get(base_url)
            
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "div.thumbnails"))
            )
            
            # æ”¶é›†æ‰€æœ‰æ´»å‹•é€£çµ
            activity_links = []
            thumbnails = self.driver.find_elements(By.CSS_SELECTOR, "div.thumbnails a")
            
            for link in thumbnails:
                href = link.get_attribute('href')
                if href and 'activity/detail' in href:
                    activity_links.append(href)
                    
            self.logger.info(f"æ‰¾åˆ° {len(activity_links)} å€‹æ´»å‹•")
            
            # è™•ç†æ¯å€‹æ´»å‹•
            events = []
            success_count = 0
            
            for index, url in enumerate(activity_links, 1):
                event_data = self.process_single_event(url, index)
                events.append(event_data)
                
                if event_data['title'] != "éŒ¯èª¤":
                    success_count += 1
                    
                # é¿å…éå¿«è«‹æ±‚
                time.sleep(1)
            
            # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
            success_rate = (success_count / len(events)) * 100 if events else 0
            
            # è¼‰å…¥ç¾æœ‰è³‡æ–™
            existing_data = self.load_existing_data('tixcraft_activities.json')
            
            # åˆä½µæ–°èˆŠè³‡æ–™
            merged_events = self.merge_data(existing_data, events)
            
            # é‡æ–°è¨ˆç®—çµ±è¨ˆè³‡æ–™
            merged_success_count = sum(1 for event in merged_events 
                                     if not all(field == "æœªæ‰¾åˆ°" for field in [
                                         event.get('date', ''),
                                         event.get('time', ''),
                                         event.get('location', ''),
                                         event.get('price', ''),
                                         event.get('sale_time', '')
                                     ]))
            merged_success_rate = (merged_success_count / len(merged_events)) * 100 if merged_events else 0
            
            # æº–å‚™æœ€çµ‚çµæœ
            result = {
                'scrape_time': time.strftime('%Y-%m-%d %H:%M:%S'),
                'last_update': time.strftime('%Y-%m-%d %H:%M:%S'),
                'total_events': len(merged_events),
                'success_count': merged_success_count,
                'success_rate': f'{merged_success_rate:.1f}%',
                'extraction_method': 'precision_field_extraction',
                'current_scrape_count': len(events),
                'current_scrape_success': success_count,
                'events': merged_events
            }
            
            # å„²å­˜çµæœåˆ°çµ±ä¸€æª”æ¡ˆ
            output_file = 'tixcraft_activities.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
                
            self.logger.info(f"æœ¬æ¬¡çˆ¬å–ï¼šæˆåŠŸè™•ç† {success_count}/{len(events)} å€‹æ´»å‹•")
            self.logger.info(f"æœ¬æ¬¡æˆåŠŸç‡ï¼š{success_rate:.1f}%")
            self.logger.info(f"ç¸½è³‡æ–™åº«ï¼š{len(merged_events)} å€‹æ´»å‹•ï¼Œæ•´é«”æˆåŠŸç‡ï¼š{merged_success_rate:.1f}%")
            self.logger.info(f"çµæœå·²æ›´æ–°è‡³ï¼š{output_file}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"çˆ¬å–éç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            return None
        finally:
            if self.driver:
                self.driver.quit()
                
def main():
    scraper = TixcraftPrecisionFieldScraper()
    result = scraper.scrape_all_events()
    
    if result:
        print(f"\n=== ğŸ¯ å¢å¼·ç‰ˆè³‡æ–™æ›´æ–°çµæœ ===")
        print(f"æ›´æ–°æ™‚é–“ï¼š{result['last_update']}")
        print(f"æœ¬æ¬¡çˆ¬å–ï¼š{result['current_scrape_count']} å€‹æ´»å‹•")
        print(f"æœ¬æ¬¡æˆåŠŸï¼š{result['current_scrape_success']} å€‹")
        print(f"è³‡æ–™åº«ç¸½è¨ˆï¼š{result['total_events']} å€‹æ´»å‹•")
        print(f"æ•´é«”æˆåŠŸç‡ï¼š{result['success_rate']}")
        print(f"æå–æ–¹æ³•ï¼š{result['extraction_method']} + JavaScript dataLayer")
        print(f"å„²å­˜æª”æ¡ˆï¼štixcraft_activities.json")
        
        # åˆ†æJavaScriptæ•¸æ“šæå–æ•ˆæœ
        js_success_count = sum(1 for event in result['events'] 
                              if event.get('js_title', 'æœªæŠ“åˆ°æ¨™é¡Œ') not in ['æœªæŠ“åˆ°æ¨™é¡Œ', 'JSæå–å¤±æ•—', 'æå–å¤±æ•—'])
        print(f"ğŸ“Š JavaScriptæˆåŠŸç‡ï¼š{js_success_count}/{result['total_events']} ({js_success_count/result['total_events']*100:.1f}%)")
        
        # é¡¯ç¤ºæœ€è¿‘æ›´æ–°çš„5å€‹æ´»å‹•ç¤ºä¾‹
        print(f"\n=== ğŸ” æœ€æ–°æ´»å‹•è³‡æ–™ç¤ºä¾‹ ===")
        recent_events = result['events'][:5]  # å–å‰5å€‹ä½œç‚ºç¤ºä¾‹
        for i, event in enumerate(recent_events, 1):
            print(f"\nã€æ´»å‹• {i}ã€‘{event['title']}")
            print(f"  ğŸ­ JSæ¨™é¡Œï¼š{event.get('js_title', 'N/A')}")
            print(f"  ğŸ“‚ åˆ†é¡ï¼š{event.get('category', 'N/A')}")
            print(f"  ğŸ® éŠæˆ²ä»£ç¢¼ï¼š{event.get('game_code', 'N/A')}")
            print(f"  ğŸ¢ ä¸»è¾¦æ–¹ï¼š{event.get('promoter', 'N/A')}")
            print(f"  ğŸ“… æ—¥æœŸï¼š{event['date']}")
            print(f"  â° æ™‚é–“ï¼š{event['time']}")
            print(f"  ğŸ“ åœ°é»ï¼š{event['location']}")
            print(f"  ğŸ’° ç¥¨åƒ¹ï¼š{event['price']}")
            print(f"  ğŸŸï¸ å”®ç¥¨æ™‚é–“ï¼š{event['sale_time']}")
        
        print(f"\nâœ… è³‡æ–™å·²æˆåŠŸæ›´æ–°åˆ° tixcraft_activities.json")
        print(f"ğŸš€ ç¾åœ¨åŒ…å«JavaScriptå¾Œå°æ•¸æ“šåŒ…æå–åŠŸèƒ½ï¼")
        print(f"ğŸ“Š ç¸½å…±ç®¡ç† {result['total_events']} å€‹æ´»å‹•è³‡æ–™")
        
    else:
        print("âŒ çˆ¬å–å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ—¥èªŒæ–‡ä»¶")

if __name__ == "__main__":
    main()